#!/usr/bin/env python3
"""
Enhanced Stage3 Pipeline Test
- KNN â†’ CSLS â†’ MCL íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
- Cross-column label matching í…ŒìŠ¤íŠ¸  
- Cluster refinement í…ŒìŠ¤íŠ¸
"""

import sys
import os
import pandas as pd
import numpy as np
from pathlib import Path

# Add current directory to path
sys.path.insert(0, str(Path(__file__).parent))

from singleton_aware_stage3_node import (
    singleton_aware_stage3_node,
    load_column_wise_data,
    process_question_singleton_aware,
    match_labels_across_columns,
    refine_clusters_by_similarity
)

def create_test_data():
    """í…ŒìŠ¤íŠ¸ìš© Stage2 ì¶œë ¥ ë°ì´í„° ìƒì„±"""
    
    # Stage2 ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = "/home/cyyoon/test_area/ai_text_classification/2.langgraph/data/stage2_output"
    os.makedirs(output_dir, exist_ok=True)
    
    # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    test_data = {
        'Question_1_Column_A': {
            'texts': [
                "The service was excellent and staff was friendly",
                "Great customer service, very helpful staff", 
                "Outstanding service quality and professional team",
                "Poor service, unhelpful staff attitude",
                "Terrible customer service experience",
                "Worst service I've ever received",
                "Average service, nothing special",
                "Decent service but could be better"
            ],
            'embeddings': np.random.randn(8, 384)  # Simulated embeddings
        },
        'Question_1_Column_B': {
            'texts': [
                "The service was excellent and staff was friendly",  # ë™ì¼ í…ìŠ¤íŠ¸
                "Great customer service, very helpful staff",        # ë™ì¼ í…ìŠ¤íŠ¸
                "Outstanding service quality and professional team", # ë™ì¼ í…ìŠ¤íŠ¸
                "Poor service, unhelpful staff attitude",           # ë™ì¼ í…ìŠ¤íŠ¸
                "Terrible customer service experience",            # ë™ì¼ í…ìŠ¤íŠ¸
                "Worst service I've ever received",                # ë™ì¼ í…ìŠ¤íŠ¸
                "Average service, nothing special",                # ë™ì¼ í…ìŠ¤íŠ¸
                "Decent service but could be better"               # ë™ì¼ í…ìŠ¤íŠ¸
            ],
            'embeddings': np.random.randn(8, 384)  # ë‹¤ë¥¸ ì„ë² ë”© (ë‹¤ë¥¸ ì»¬ëŸ¼)
        },
        'Question_2_Column_A': {
            'texts': [
                "The product quality is amazing",
                "Excellent product, very satisfied",
                "High quality product, recommended",
                "Poor product quality, disappointed", 
                "Low quality, not worth the price",
                "Product quality is unacceptable"
            ],
            'embeddings': np.random.randn(6, 384)
        }
    }
    
    # CSV íŒŒì¼ë¡œ ì €ì¥
    for name, data in test_data.items():
        df = pd.DataFrame({
            'text': data['texts'],
            'embedding_col': [f"embed_{i}" for i in range(len(data['texts']))]
        })
        
        # ì„ë² ë”©ì„ ë³„ë„ ì»¬ëŸ¼ë“¤ë¡œ ì €ì¥
        embeddings = data['embeddings']
        for i in range(embeddings.shape[1]):
            df[f'embed_{i}'] = embeddings[:, i]
        
        # CSV ì €ì¥
        csv_path = os.path.join(output_dir, f"{name}.csv")
        df.to_csv(csv_path, index=False)
        print(f"âœ… Created: {csv_path}")
    
    print(f"\nğŸ“‚ Test data created in: {output_dir}")
    return output_dir

def test_data_loading(output_dir):
    """ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸"""
    
    print("\n" + "="*50)
    print("ğŸ” Testing Data Loading")
    print("="*50)
    
    try:
        data = load_column_wise_data(output_dir)
        
        print(f"âœ… Loaded {len(data)} questions")
        for question_id, question_data in data.items():
            print(f"   ğŸ“‹ {question_id}: {len(question_data)} columns")
            for column_name, (df, embeddings) in question_data.items():
                print(f"      ğŸ“„ {column_name}: {len(df)} rows, {embeddings.shape}")
        
        return data
        
    except Exception as e:
        print(f"âŒ Data loading failed: {e}")
        import traceback
        traceback.print_exc()
        return None

def test_single_question_processing(data):
    """ë‹¨ì¼ ë¬¸í•­ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    
    print("\n" + "="*50)
    print("ğŸ¯ Testing Single Question Processing")
    print("="*50)
    
    if not data:
        print("âŒ No data available for testing")
        return
    
    # ì²« ë²ˆì§¸ ë¬¸í•­ ì„ íƒ
    question_id = list(data.keys())[0]
    question_data = data[question_id]
    
    print(f"ğŸ“‹ Testing question: {question_id}")
    
    try:
        result = process_question_singleton_aware(question_id, question_data)
        
        print(f"\nğŸ“Š Results Summary:")
        print(f"   â€¢ Total columns: {result['n_columns']}")
        print(f"   â€¢ Total clusters: {result['total_clusters']}")
        print(f"   â€¢ Total singletons: {result['total_singletons']}")
        print(f"   â€¢ Algorithms used: {result['algorithms_used']}")
        print(f"   â€¢ Avg NMI: {result['avg_nmi']:.3f}")
        print(f"   â€¢ Avg Adj ARI: {result['avg_adj_ari']:.3f}")
        print(f"   â€¢ Avg Combined Score: {result['avg_combined_score']:.3f}")
        
        print(f"\nğŸ“‹ Column Details:")
        for col_result in result['column_results']:
            print(f"   ğŸ”¹ {col_result['column']}: {col_result['n_clusters']} clusters, "
                  f"{col_result['n_singletons']} singletons, "
                  f"score={col_result.get('combined_score', 0):.3f}")
        
        return result
        
    except Exception as e:
        print(f"âŒ Single question processing failed: {e}")
        import traceback
        traceback.print_exc()
        return None

def test_full_stage3_pipeline(output_dir):
    """ì „ì²´ Stage3 íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
    
    print("\n" + "="*50)
    print("ğŸš€ Testing Full Stage3 Pipeline")
    print("="*50)
    
    # Mock state ìƒì„±
    test_state = {
        'output_dir': output_dir,
        'stage2_completed': True
    }
    
    try:
        result_state = singleton_aware_stage3_node(test_state)
        
        if 'stage3_results' in result_state and 'error' not in result_state['stage3_results']:
            results = result_state['stage3_results']
            
            print(f"\nğŸ‰ Stage3 Pipeline Success!")
            print(f"   â€¢ Processing type: {results['processing_type']}")
            print(f"   â€¢ Questions processed: {results['overall_summary']['total_questions']}")
            print(f"   â€¢ Total clusters: {results['overall_summary']['total_clusters']}")
            print(f"   â€¢ Total singletons: {results['overall_summary']['total_singletons']}")
            print(f"   â€¢ Singleton ratio: {results['overall_summary']['singleton_ratio']:.3f}")
            print(f"   â€¢ Overall NMI: {results['overall_summary']['overall_avg_nmi']:.3f}")
            print(f"   â€¢ Overall Adj ARI: {results['overall_summary']['overall_avg_adj_ari']:.3f}")
            print(f"   â€¢ Overall Combined Score: {results['overall_summary']['overall_avg_combined_score']:.3f}")
            print(f"   â€¢ Quality Distribution: {results['overall_summary']['quality_distribution']}")
            
            return True
        else:
            print(f"âŒ Stage3 Pipeline failed: {result_state.get('stage3_results', {}).get('error', 'Unknown error')}")
            return False
            
    except Exception as e:
        print(f"âŒ Full pipeline test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def run_enhanced_stage3_tests():
    """í–¥ìƒëœ Stage3 í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    
    print("ğŸ§ª Enhanced Stage3 Pipeline Tests")
    print("="*60)
    print("Testing improvements:")
    print("1. KNN â†’ CSLS â†’ MCL algorithm order")
    print("2. Cross-column label matching")
    print("3. Cluster refinement by similarity")
    print("4. NMI/ARI evaluation system")
    print("="*60)
    
    # 1. í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    output_dir = create_test_data()
    
    # 2. ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸
    data = test_data_loading(output_dir)
    
    # 3. ë‹¨ì¼ ë¬¸í•­ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
    single_result = test_single_question_processing(data)
    
    # 4. ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
    pipeline_success = test_full_stage3_pipeline(output_dir)
    
    # 5. ê²°ê³¼ ìš”ì•½
    print("\n" + "="*60)
    print("ğŸ“‹ Test Summary")
    print("="*60)
    
    if data:
        print("âœ… Data loading: PASSED")
    else:
        print("âŒ Data loading: FAILED")
    
    if single_result:
        print("âœ… Single question processing: PASSED")
    else:
        print("âŒ Single question processing: FAILED")
    
    if pipeline_success:
        print("âœ… Full pipeline: PASSED")
    else:
        print("âŒ Full pipeline: FAILED")
    
    if data and single_result and pipeline_success:
        print("\nğŸ‰ All Enhanced Stage3 tests PASSED!")
        print("âœ… KNN â†’ CSLS â†’ MCL pipeline working")
        print("âœ… Cross-column label matching working")
        print("âœ… Cluster refinement working")
        print("âœ… NMI/ARI evaluation working")
    else:
        print("\nâš ï¸  Some tests failed. Check the logs above.")

if __name__ == "__main__":
    run_enhanced_stage3_tests()