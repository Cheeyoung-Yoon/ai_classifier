"""
Performance analysis tool for Stage 3 MCL clustering.
ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ê³¼ ì‹¤í–‰ ì‹œê°„ì„ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤.
"""
import time
import psutil
import os
import numpy as np
import pandas as pd

def monitor_memory_usage():
    """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸"""
    process = psutil.Process(os.getpid())
    memory_mb = process.memory_info().rss / 1024 / 1024
    return memory_mb

def test_mcl_performance():
    """MCL ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("ğŸ” MCL Performance Analysis")
    print("=" * 50)
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
    initial_memory = monitor_memory_usage()
    print(f"Initial memory: {initial_memory:.1f} MB")
    
    # ë‹¤ì–‘í•œ í¬ê¸°ì˜ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
    sizes = [50, 100, 200, 500]
    
    for size in sizes:
        print(f"\n--- Testing with {size} samples ---")
        
        # ë°ì´í„° ìƒì„±
        start_time = time.time()
        embeddings = np.random.randn(size, 128)
        data_gen_time = time.time() - start_time
        
        memory_after_data = monitor_memory_usage()
        print(f"Data generation: {data_gen_time:.3f}s, Memory: {memory_after_data:.1f} MB")
        
        # MCL í…ŒìŠ¤íŠ¸
        try:
            from mcl_pipeline import MCLPipeline
            
            start_time = time.time()
            mcl = MCLPipeline(inflation=2.0, max_iters=50)
            mcl_time = time.time() - start_time
            
            memory_after_mcl = monitor_memory_usage()
            print(f"MCL init: {mcl_time:.3f}s, Memory: {memory_after_mcl:.1f} MB")
            
            # Fit í…ŒìŠ¤íŠ¸
            start_time = time.time()
            mcl.fit(embeddings, k=min(10, size-1))
            fit_time = time.time() - start_time
            
            memory_after_fit = monitor_memory_usage()
            print(f"MCL fit: {fit_time:.3f}s, Memory: {memory_after_fit:.1f} MB")
            
            # ê²°ê³¼ í™•ì¸
            summary = mcl.get_cluster_summary()
            print(f"Clusters found: {summary.get('n_clusters', 0)}")
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            del mcl, embeddings
            
        except Exception as e:
            print(f"âŒ MCL test failed: {e}")
            
        current_memory = monitor_memory_usage()
        memory_diff = current_memory - initial_memory
        print(f"Memory usage: {current_memory:.1f} MB (+{memory_diff:.1f} MB)")
        
        if memory_diff > 100:  # 100MB ì´ìƒ ì¦ê°€
            print("âš ï¸  Potential memory leak detected!")

def test_data_loading_performance():
    """ë°ì´í„° ë¡œë”© ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” Data Loading Performance Analysis")
    print("=" * 50)
    
    # ì‹¤ì œ ë°ì´í„° íŒŒì¼ í…ŒìŠ¤íŠ¸
    test_file = "/home/cyyoon/test_area/ai_text_classification/2.langgraph/data/test/temp_data/stage2_results/stage2_ë¬¸4_img_20250918_112537.csv"
    
    if not os.path.exists(test_file):
        print(f"âŒ Test file not found: {test_file}")
        return
    
    initial_memory = monitor_memory_usage()
    print(f"Initial memory: {initial_memory:.1f} MB")
    
    # CSV ë¡œë”© í…ŒìŠ¤íŠ¸
    start_time = time.time()
    df = pd.read_csv(test_file)
    load_time = time.time() - start_time
    
    memory_after_load = monitor_memory_usage()
    print(f"CSV loading: {load_time:.3f}s, Memory: {memory_after_load:.1f} MB")
    print(f"Data shape: {df.shape}")
    
    # ì„ë² ë”© íŒŒì‹± í…ŒìŠ¤íŠ¸
    embed_col = 'embed_text_1'
    embeddings = []
    
    start_time = time.time()
    for idx, row in df.iterrows():
        embed_str = row[embed_col]
        if pd.notna(embed_str) and embed_str != '':
            try:
                if isinstance(embed_str, str) and embed_str.startswith('['):
                    embed_array = eval(embed_str)  # ì‹¤ì œë¡œëŠ” ast.literal_eval ì‚¬ìš©
                    embeddings.append(embed_array)
                    if len(embeddings) >= 100:  # ì œí•œ
                        break
            except:
                continue
                
    parse_time = time.time() - start_time
    memory_after_parse = monitor_memory_usage()
    
    print(f"Embedding parsing: {parse_time:.3f}s, Memory: {memory_after_parse:.1f} MB")
    print(f"Parsed embeddings: {len(embeddings)}")
    
    if len(embeddings) > 0:
        embeddings_array = np.array(embeddings)
        print(f"Embeddings shape: {embeddings_array.shape}")
        
        memory_after_array = monitor_memory_usage()
        print(f"Array conversion: Memory: {memory_after_array:.1f} MB")

def identify_bottlenecks():
    """ë³‘ëª© êµ¬ê°„ ì‹ë³„"""
    print("\nğŸ” Bottleneck Analysis")
    print("=" * 50)
    
    # ê° ë‹¨ê³„ë³„ ì‹œê°„ ì¸¡ì •
    stages = {
        "Data loading": test_simple_csv_load,
        "Embedding parsing": test_embedding_parsing,
        "MCL clustering": test_mcl_clustering,
        "Evaluation": test_evaluation_performance
    }
    
    for stage_name, test_func in stages.items():
        start_time = time.time()
        start_memory = monitor_memory_usage()
        
        try:
            test_func()
            elapsed = time.time() - start_time
            end_memory = monitor_memory_usage()
            memory_used = end_memory - start_memory
            
            print(f"{stage_name:20}: {elapsed:.3f}s, Memory: +{memory_used:.1f} MB")
            
            if elapsed > 5.0:  # 5ì´ˆ ì´ìƒ
                print(f"âš ï¸  {stage_name} is slow!")
            if memory_used > 50:  # 50MB ì´ìƒ
                print(f"âš ï¸  {stage_name} uses too much memory!")
                
        except Exception as e:
            print(f"{stage_name:20}: FAILED - {e}")

def test_simple_csv_load():
    """ê°„ë‹¨í•œ CSV ë¡œë”© í…ŒìŠ¤íŠ¸"""
    test_file = "/home/cyyoon/test_area/ai_text_classification/2.langgraph/data/test/temp_data/stage2_results/stage2_ë¬¸4_img_20250918_112537.csv"
    if os.path.exists(test_file):
        df = pd.read_csv(test_file)
        return len(df)
    return 0

def test_embedding_parsing():
    """ì„ë² ë”© íŒŒì‹± í…ŒìŠ¤íŠ¸"""
    # ê°€ì§œ ì„ë² ë”© ë¬¸ìì—´
    embed_str = str(np.random.randn(768).tolist())
    embeddings = []
    for _ in range(100):
        embed_array = eval(embed_str)
        embeddings.append(embed_array)
    return len(embeddings)

def test_mcl_clustering():
    """MCL í´ëŸ¬ìŠ¤í„°ë§ í…ŒìŠ¤íŠ¸"""
    from mcl_pipeline import MCLPipeline
    embeddings = np.random.randn(50, 128)
    mcl = MCLPipeline(inflation=2.0, max_iters=20)
    mcl.fit(embeddings, k=10)
    return mcl.get_cluster_summary()['n_clusters']

def test_evaluation_performance():
    """í‰ê°€ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    from evaluation import mcl_scoring_function
    true_labels = np.random.randint(0, 5, size=100)
    pred_labels = np.random.randint(0, 5, size=100)
    scores = mcl_scoring_function(true_labels, pred_labels)
    return scores['metrics']['nmi']

if __name__ == "__main__":
    print("ğŸš€ Performance Analysis Starting...")
    
    try:
        test_mcl_performance()
        test_data_loading_performance()
        identify_bottlenecks()
        
        print("\nâœ… Performance analysis completed!")
        
    except Exception as e:
        print(f"âŒ Performance analysis failed: {e}")
        import traceback
        traceback.print_exc()