"""
MCL íŒŒë¼ë¯¸í„°ë¥¼ sentence embeddingì— ìµœì í™”
"""
import numpy as np
import time
from sklearn.metrics.pairwise import cosine_similarity
from mcl_pipeline import MCLPipeline
from evaluation import mcl_scoring_function

def optimize_mcl_for_sentences():
    """Sentence embeddingì— ìµœì í™”ëœ MCL íŒŒë¼ë¯¸í„° ì°¾ê¸°"""
    print("ğŸ”§ MCL Parameter Optimization for Sentence Embeddings")
    print("=" * 60)
    
    # ë” í˜„ì‹¤ì ì¸ sentence embedding ì‹œë®¬ë ˆì´ì…˜
    np.random.seed(42)
    
    # 3ê°œ ê·¸ë£¹ì˜ ë¬¸ì¥ë“¤ (ë” í˜„ì‹¤ì ì¸ ìœ ì‚¬ë„)
    # ê·¸ë£¹ 1: ì—°ë¹„ ê´€ë ¨ ë¬¸ì¥ë“¤
    fuel_sentences = np.random.randn(25, 128) * 0.3 + np.array([0.8, 0.2] + [0]*126)
    
    # ê·¸ë£¹ 2: ë””ìì¸ ê´€ë ¨ ë¬¸ì¥ë“¤  
    design_sentences = np.random.randn(25, 128) * 0.3 + np.array([0.2, 0.8] + [0]*126)
    
    # ê·¸ë£¹ 3: ì„±ëŠ¥ ê´€ë ¨ ë¬¸ì¥ë“¤
    performance_sentences = np.random.randn(25, 128) * 0.3 + np.array([-0.5, -0.5] + [0]*126)
    
    embeddings = np.vstack([fuel_sentences, design_sentences, performance_sentences])
    true_labels = np.array([0]*25 + [1]*25 + [2]*25)
    
    print(f"Test data: {embeddings.shape[0]} sentence embeddings, 3 semantic groups")
    
    # ìœ ì‚¬ë„ ë¶„ì„
    similarity_matrix = cosine_similarity(embeddings)
    print(f"Similarity range: {similarity_matrix.min():.3f} to {similarity_matrix.max():.3f}")
    print(f"Average similarity: {similarity_matrix.mean():.3f}")
    
    # sentence embeddingì— ë§ëŠ” íŒŒë¼ë¯¸í„° ë²”ìœ„ í…ŒìŠ¤íŠ¸
    inflation_values = [1.1, 1.2, 1.3, 1.4, 1.5, 1.8, 2.0]
    k_values = [3, 5, 8, 10, 15, 20]
    max_iter_values = [20, 50, 100]
    
    best_score = -1
    best_params = None
    best_details = None
    results = []
    
    print(f"\nTesting {len(inflation_values)} Ã— {len(k_values)} Ã— {len(max_iter_values)} = {len(inflation_values) * len(k_values) * len(max_iter_values)} combinations...")
    
    for inflation in inflation_values:
        for k in k_values:
            for max_iter in max_iter_values:
                if k >= len(embeddings):
                    continue
                    
                try:
                    start_time = time.time()
                    mcl = MCLPipeline(inflation=inflation, max_iters=max_iter)
                    mcl.fit(embeddings, k=k)
                    fit_time = time.time() - start_time
                    
                    summary = mcl.get_cluster_summary()
                    n_clusters = summary["n_clusters"]
                    
                    # í‰ê°€
                    scores = mcl_scoring_function(true_labels, mcl.cluster_labels)
                    nmi = scores['metrics']['nmi']
                    ari = scores['metrics']['ari']
                    composite_score = (nmi + ari) / 2
                    
                    singleton_ratio = scores['cluster_stats']['pred_singleton_ratio']
                    
                    result = {
                        'inflation': inflation,
                        'k': k,
                        'max_iter': max_iter,
                        'n_clusters': n_clusters,
                        'nmi': nmi,
                        'ari': ari,
                        'composite_score': composite_score,
                        'singleton_ratio': singleton_ratio,
                        'fit_time': fit_time
                    }
                    results.append(result)
                    
                    # ì¢‹ì€ í´ëŸ¬ìŠ¤í„°ë§ ì¡°ê±´:
                    # 1. ì ë‹¹í•œ í´ëŸ¬ìŠ¤í„° ìˆ˜ (2-10ê°œ)
                    # 2. ë‚®ì€ singleton ë¹„ìœ¨ (<0.3)
                    # 3. ë†’ì€ NMI/ARI ì ìˆ˜
                    if (2 <= n_clusters <= 10 and 
                        singleton_ratio < 0.3 and 
                        composite_score > best_score):
                        
                        best_score = composite_score
                        best_params = {
                            'inflation': inflation,
                            'k': k, 
                            'max_iter': max_iter
                        }
                        best_details = result
                        
                except Exception as e:
                    print(f"Failed: inflation={inflation}, k={k}, max_iter={max_iter} - {e}")
                    continue
    
    # ê²°ê³¼ ë¶„ì„
    print(f"\nğŸ“Š Results Analysis:")
    print(f"Total tested combinations: {len(results)}")
    
    if best_params:
        print(f"\nğŸ† Best Parameters Found:")
        print(f"  Inflation: {best_params['inflation']}")
        print(f"  K neighbors: {best_params['k']}")
        print(f"  Max iterations: {best_params['max_iter']}")
        print(f"  Clusters found: {best_details['n_clusters']}")
        print(f"  NMI: {best_details['nmi']:.3f}")
        print(f"  ARI: {best_details['ari']:.3f}")
        print(f"  Composite score: {best_details['composite_score']:.3f}")
        print(f"  Singleton ratio: {best_details['singleton_ratio']:.3f}")
        print(f"  Fit time: {best_details['fit_time']:.3f}s")
    else:
        print("âŒ No good parameters found!")
        
        # ì°¨ì„ ì±…: ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ê°€ì§„ ê²°ê³¼ë“¤ ë³´ê¸°
        if results:
            results.sort(key=lambda x: x['composite_score'], reverse=True)
            print(f"\nğŸ“‹ Top 5 Results (by composite score):")
            for i, result in enumerate(results[:5]):
                print(f"  {i+1}. inflation={result['inflation']}, k={result['k']}, "
                      f"clusters={result['n_clusters']}, score={result['composite_score']:.3f}, "
                      f"singleton_ratio={result['singleton_ratio']:.3f}")
    
    return best_params, results

def test_optimized_parameters():
    """ìµœì í™”ëœ íŒŒë¼ë¯¸í„°ë¡œ í…ŒìŠ¤íŠ¸"""
    print(f"\nğŸ§ª Testing Optimized Parameters")
    print("=" * 40)
    
    best_params, _ = optimize_mcl_for_sentences()
    
    if not best_params:
        print("âŒ No optimized parameters to test")
        return
    
    # ë” í° í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ê²€ì¦
    np.random.seed(123)  # ë‹¤ë¥¸ ì‹œë“œë¡œ ê²€ì¦
    
    # 5ê°œ ê·¸ë£¹ìœ¼ë¡œ ë” ì–´ë ¤ìš´ í…ŒìŠ¤íŠ¸
    groups = []
    for i in range(5):
        center = np.random.randn(128) * 2
        group_data = np.random.randn(20, 128) * 0.4 + center
        groups.append(group_data)
    
    embeddings = np.vstack(groups)
    true_labels = np.array([i for i in range(5) for _ in range(20)])
    
    print(f"Validation data: {embeddings.shape[0]} embeddings, 5 groups")
    
    # ìµœì í™”ëœ íŒŒë¼ë¯¸í„°ë¡œ í…ŒìŠ¤íŠ¸
    mcl = MCLPipeline(
        inflation=best_params['inflation'],
        max_iters=best_params['max_iter']
    )
    
    start_time = time.time()
    mcl.fit(embeddings, k=best_params['k'])
    fit_time = time.time() - start_time
    
    summary = mcl.get_cluster_summary()
    scores = mcl_scoring_function(true_labels, mcl.cluster_labels)
    
    print(f"Validation Results:")
    print(f"  Clusters found: {summary['n_clusters']}")
    print(f"  NMI: {scores['metrics']['nmi']:.3f}")
    print(f"  ARI: {scores['metrics']['ari']:.3f}")
    print(f"  Singleton ratio: {scores['cluster_stats']['pred_singleton_ratio']:.3f}")
    print(f"  Fit time: {fit_time:.3f}s")
    
    # KMeansì™€ ë¹„êµ
    from sklearn.cluster import KMeans
    kmeans = KMeans(n_clusters=5, random_state=42)
    kmeans_labels = kmeans.fit_predict(embeddings)
    kmeans_scores = mcl_scoring_function(true_labels, kmeans_labels)
    
    print(f"\nKMeans comparison:")
    print(f"  NMI: {kmeans_scores['metrics']['nmi']:.3f}")
    print(f"  ARI: {kmeans_scores['metrics']['ari']:.3f}")
    
    if scores['metrics']['nmi'] > 0.5 and scores['metrics']['ari'] > 0.3:
        print("âœ… Optimized MCL performs reasonably well!")
    else:
        print("âŒ MCL still underperforming compared to KMeans")

if __name__ == "__main__":
    optimize_mcl_for_sentences()
    test_optimized_parameters()
    
    print("\nâœ… MCL optimization completed!")