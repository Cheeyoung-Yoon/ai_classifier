#!/usr/bin/env python3
"""
Real Data Stage3 Pipeline Test
ì‹¤ì œ stage2 ì¶œë ¥ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ Stage3 íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
"""

import sys
import os
import pandas as pd
import numpy as np
from pathlib import Path

# Add current directory to path
sys.path.insert(0, str(Path(__file__).parent))

from singleton_aware_stage3_node import singleton_aware_stage3_node

def test_with_real_data():
    """ì‹¤ì œ Stage2 ì¶œë ¥ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸"""
    
    print("ğŸ” Real Data Stage3 Pipeline Test")
    print("=" * 60)
    
    # ì‹¤ì œ Stage2 ë°ì´í„° ë””ë ‰í† ë¦¬
    real_data_dir = "/home/cyyoon/test_area/ai_text_classification/2.langgraph/data/test/temp_data/stage2_results copy"
    
    if not os.path.exists(real_data_dir):
        print(f"âŒ Real data directory not found: {real_data_dir}")
        return False
    
    # CSV íŒŒì¼ë“¤ í™•ì¸
    import glob
    csv_files = glob.glob(os.path.join(real_data_dir, "*.csv"))
    print(f"ğŸ“‚ Found {len(csv_files)} CSV files:")
    for csv_file in csv_files:
        file_name = os.path.basename(csv_file)
        print(f"   ğŸ“„ {file_name}")
    
    # Mock state ìƒì„±
    test_state = {
        'output_dir': real_data_dir,
        'stage2_completed': True
    }
    
    try:
        print(f"\nğŸš€ Running Stage3 Pipeline on Real Data...")
        print("=" * 60)
        
        result_state = singleton_aware_stage3_node(test_state)
        
        if 'stage3_results' in result_state and 'error' not in result_state['stage3_results']:
            results = result_state['stage3_results']
            
            print(f"\nğŸ‰ Stage3 Pipeline Success!")
            print(f"   â€¢ Processing type: {results['processing_type']}")
            print(f"   â€¢ Questions processed: {results['overall_summary']['total_questions']}")
            print(f"   â€¢ Total clusters: {results['overall_summary']['total_clusters']}")
            print(f"   â€¢ Total singletons: {results['overall_summary']['total_singletons']}")
            print(f"   â€¢ Singleton ratio: {results['overall_summary']['singleton_ratio']:.3f}")
            print(f"   â€¢ Overall NMI: {results['overall_summary']['overall_avg_nmi']:.3f}")
            print(f"   â€¢ Overall Adj ARI: {results['overall_summary']['overall_avg_adj_ari']:.3f}")
            print(f"   â€¢ Overall Combined Score: {results['overall_summary']['overall_avg_combined_score']:.3f}")
            print(f"   â€¢ Quality Distribution: {results['overall_summary']['quality_distribution']}")
            
            # ë¬¸í•­ë³„ ìƒì„¸ ê²°ê³¼
            print(f"\nğŸ“‹ Question Details:")
            for question_id, question_result in results['questions'].items():
                print(f"\n   ğŸ“Œ {question_id}:")
                print(f"      â€¢ Columns: {question_result['n_columns']}")
                print(f"      â€¢ Clusters: {question_result['total_clusters']}")
                print(f"      â€¢ Singletons: {question_result['total_singletons']}")
                print(f"      â€¢ Avg Combined Score: {question_result['avg_combined_score']:.3f}")
                print(f"      â€¢ Quality Distribution: {question_result['quality_distribution']}")
                
                # ì»¬ëŸ¼ë³„ ìƒì„¸
                for col_result in question_result['column_results']:
                    quality = col_result.get('quality_assessment', 'UNKNOWN')
                    score = col_result.get('combined_score', 0)
                    algorithm = col_result.get('algorithm', 'unknown')
                    print(f"         ğŸ”¸ {col_result['column']}: {col_result['n_clusters']} clusters, "
                          f"{col_result['n_singletons']} singletons, {algorithm}, "
                          f"score={score:.3f} ({quality})")
            
            # í’ˆì§ˆ ê¸°ì¤€ë³„ ë¶„ì„
            print(f"\nğŸ“Š Quality Analysis (Updated Criteria):")
            print(f"   â€¢ EXCELLENT (â‰¥0.96): Count = {results['overall_summary']['quality_distribution'].get('EXCELLENT', 0)}")
            print(f"   â€¢ GOOD (â‰¥0.88): Count = {results['overall_summary']['quality_distribution'].get('GOOD', 0)}")
            print(f"   â€¢ FAIR (â‰¥0.83): Count = {results['overall_summary']['quality_distribution'].get('FAIR', 0)}")
            print(f"   â€¢ IMPROVE (â‰¥0.72): Count = {results['overall_summary']['quality_distribution'].get('IMPROVE', 0)}")
            print(f"   â€¢ FAIL (<0.72): Count = {results['overall_summary']['quality_distribution'].get('FAIL', 0)}")
            
            return True
        else:
            error_msg = result_state.get('stage3_results', {}).get('error', 'Unknown error')
            print(f"âŒ Stage3 Pipeline failed: {error_msg}")
            return False
            
    except Exception as e:
        print(f"âŒ Test failed with exception: {e}")
        import traceback
        traceback.print_exc()
        return False

def analyze_data_structure(data_dir):
    """ë°ì´í„° êµ¬ì¡° ë¶„ì„"""
    
    print(f"\nğŸ” Data Structure Analysis")
    print("=" * 40)
    
    import glob
    csv_files = glob.glob(os.path.join(data_dir, "*.csv"))
    
    for csv_file in csv_files[:3]:  # ì²˜ìŒ 3ê°œ íŒŒì¼ë§Œ ë¶„ì„
        file_name = os.path.basename(csv_file)
        print(f"\nğŸ“„ {file_name}:")
        
        try:
            df = pd.read_csv(csv_file)
            print(f"   â€¢ Rows: {len(df)}")
            print(f"   â€¢ Columns: {list(df.columns)}")
            
            # ë¬¸í•­ ì •ë³´
            if 'question_id' in df.columns:
                unique_questions = df['question_id'].unique()
                print(f"   â€¢ Questions: {unique_questions}")
            
            # í…ìŠ¤íŠ¸ ì»¬ëŸ¼ í™•ì¸
            text_cols = [col for col in df.columns if col.startswith('text_')]
            print(f"   â€¢ Text columns: {text_cols}")
            
            # ì„ë² ë”© ì»¬ëŸ¼ í™•ì¸
            embed_cols = [col for col in df.columns if col.startswith('embed_')]
            print(f"   â€¢ Embedding columns: {len(embed_cols)} columns")
            
            # ìƒ˜í”Œ ë°ì´í„°
            if len(df) > 0:
                print(f"   â€¢ Sample text: {df.iloc[0].get('text_1', 'N/A')}")
                
        except Exception as e:
            print(f"   âŒ Error reading {file_name}: {e}")

if __name__ == "__main__":
    # ì‹¤ì œ ë°ì´í„° ë””ë ‰í† ë¦¬
    real_data_dir = "/home/cyyoon/test_area/ai_text_classification/2.langgraph/data/test/temp_data/stage2_results copy"
    
    # 1. ë°ì´í„° êµ¬ì¡° ë¶„ì„
    analyze_data_structure(real_data_dir)
    
    # 2. ì‹¤ì œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
    success = test_with_real_data()
    
    print(f"\n" + "=" * 60)
    if success:
        print("ğŸ‰ Real Data Test PASSED!")
        print("âœ… Updated quality criteria applied")
        print("âœ… Real stage2 data processed successfully")
    else:
        print("âŒ Real Data Test FAILED!")
        print("Please check the logs above for details")
    print("=" * 60)