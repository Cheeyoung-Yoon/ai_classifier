#!/usr/bin/env python3
"""
ì‹¤ì œ stored state ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ Stage3 Two-Phase ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
"""

import json
import pandas as pd
import numpy as np
import ast
from pathlib import Path
import sys
import os
from typing import Dict, Any, List

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from graph.state import GraphState
from nodes.stage3_classification.phase1_primary_labeling import Phase1PrimaryLabeling
from nodes.stage3_classification.phase2_secondary_labeling import Phase2SecondaryLabeling
from nodes.stage3_classification.quality_assessment import QualityAssessmentTools

def load_state_file(state_file_path: str) -> Dict[str, Any]:
    """ì €ì¥ëœ state íŒŒì¼ ë¡œë“œ"""
    print(f"Loading state file: {state_file_path}")
    
    with open(state_file_path, 'r', encoding='utf-8') as f:
        state_data = json.load(f)
    
    print(f"âœ… State file loaded successfully")
    print(f"Current stage: {state_data.get('current_stage', 'Unknown')}")
    print(f"Pipeline ID: {state_data.get('pipeline_id', 'Unknown')}")
    
    return state_data

def load_stage2_csv_data(csv_path: str) -> pd.DataFrame:
    """Stage2 ê²°ê³¼ CSV íŒŒì¼ ë¡œë“œ"""
    print(f"Loading CSV data: {csv_path}")
    
    # CSV íŒŒì¼ ì½ê¸° (ì²« ë²ˆì§¸ ì—´ì´ ì¸ë±ìŠ¤ê°€ ë˜ì§€ ì•Šë„ë¡)
    df = pd.read_csv(csv_path, index_col=0)
    
    print(f"âœ… CSV data loaded: {len(df)} rows")
    print(f"Columns: {list(df.columns)}")
    
    return df

def parse_embedding_vector(embedding_str: str) -> np.ndarray:
    """ë¬¸ìì—´ë¡œ ì €ì¥ëœ embedding ë²¡í„°ë¥¼ numpy arrayë¡œ ë³€í™˜"""
    try:
        # ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ íŒŒì‹±
        embedding_list = ast.literal_eval(embedding_str)
        return np.array(embedding_list, dtype=np.float32)
    except Exception as e:
        print(f"âš ï¸  Error parsing embedding: {e}")
        return None

def prepare_test_data(state_data: Dict[str, Any], question_id: str) -> Dict[str, Any]:
    """íŠ¹ì • ì§ˆë¬¸ì˜ ë°ì´í„°ë¥¼ ì¤€ë¹„"""
    print(f"\n=== Preparing test data for question: {question_id} ===")
    
    matched_questions = state_data.get('matched_questions', {})
    
    if question_id not in matched_questions:
        print(f"âŒ Question {question_id} not found in matched_questions")
        return None
    
    question_data = matched_questions[question_id]
    stage2_data = question_data.get('stage2_data')
    
    if not stage2_data:
        print(f"âŒ No stage2_data found for question {question_id}")
        return None
    
    csv_path = stage2_data.get('csv_path')
    if not csv_path or not os.path.exists(csv_path):
        print(f"âŒ CSV file not found: {csv_path}")
        return None
    
    # CSV ë°ì´í„° ë¡œë“œ
    df = load_stage2_csv_data(csv_path)
    
    # í…ìŠ¤íŠ¸ì™€ ì„ë² ë”© ë°ì´í„° ì¤€ë¹„
    texts = []
    embeddings = []
    
    print("Processing rows...")
    print(f"CSV columns: {df.columns.tolist()}")
    
    # CSVì—ì„œ í…ìŠ¤íŠ¸ì™€ ì„ë² ë”© ì»¬ëŸ¼ ìŒ ì°¾ê¸°
    text_embed_pairs = []
    for col in df.columns:
        if col.startswith('text_'):
            # ëŒ€ì‘í•˜ëŠ” ì„ë² ë”© ì»¬ëŸ¼ ì°¾ê¸°
            text_num = col.split('_')[1]
            embed_col = f'embed_text_{text_num}'
            if embed_col in df.columns:
                text_embed_pairs.append((col, embed_col))
    
    print(f"Found text-embedding pairs: {text_embed_pairs}")
    
    # ê° text-embedding ìŒì—ì„œ ë°ì´í„° ì¶”ì¶œ
    for text_col, embed_col in text_embed_pairs:
        for idx, row in df.iterrows():
            text = row[text_col]
            embedding_str = row[embed_col]
            
            # ë¹ˆ ê°’ ì²´í¬
            if pd.isna(text) or pd.isna(embedding_str) or text.strip() == "":
                continue
            
            # ì„ë² ë”© íŒŒì‹±
            embedding = parse_embedding_vector(embedding_str)
            if embedding is not None:
                texts.append(text.strip())
                embeddings.append(embedding)
    
    print(f"âœ… Prepared {len(texts)} samples")
    print(f"Sample texts: {texts[:3] if len(texts) >= 3 else texts}")
    
    # ë”•ì…”ë„ˆë¦¬ë¡œ ë°ì´í„° êµ¬ì„± (GraphState ìƒì„±ì ë¬¸ì œ íšŒí”¼)
    test_state = {
        'current_question_id': question_id,
        'question_type': question_data['question_info']['question_type'],
        
        # ì‹¤ì œ í…ìŠ¤íŠ¸ì™€ ì„ë² ë”© ë°ì´í„°
        'stage2_texts': texts,
        'stage2_embeddings': np.array(embeddings) if embeddings else np.array([]),
        
        # Stage3 Phase1 Configuration
        'stage3_phase1_config': {
            # kNN parameters
            'knn_k': min(30, len(texts) // 2) if len(texts) > 10 else max(3, len(texts) // 3),
            'knn_metric': 'cosine',
            'mutual_knn': True,
            
            # CSLS parameters
            'csls_neighborhood_size': 10,
            'csls_threshold': 0.1,
            'top_m_edges': 20,
            'prune_bottom_percentile': 30,
            
            # MCL parameters
            'mcl_inflation': 2.0,
            'mcl_expansion': 2,
            'mcl_pruning': 1e-3,
            'mcl_max_iters': 100,
            'mcl_convergence_check': True,
            
            # Singleton and small cluster handling
            'allow_singletons': True,
            'merge_small_clusters': True,
            'min_cluster_size': 2,
            'small_cluster_threshold': 3,
            
            # Quality assessment
            'compute_subset_score': True,
            'compute_cluster_quality': True
        },
        
        # Stage3 Phase2 Configuration
        'stage3_phase2_config': {
            'edge_threshold': 0.4,
            'community_algorithm': 'louvain',
            'resolution': 1.0,
            'min_community_size': 2,
            'semantic_weight': 0.7,
            'frequency_weight': 0.3
        },
        
        # ê¸°íƒ€ í•„ìˆ˜ í•„ë“œë“¤
        'current_stage': 'STAGE3_TWO_PHASE_TEST',
        'pipeline_id': state_data.get('pipeline_id', 'real_data_test'),
        'project_directory_structure': state_data.get('project_directory_structure', {}),
    }
    
    return test_state

def run_two_phase_test(test_state: Dict[str, Any]) -> Dict[str, Any]:
    """Two-phase ì‹œìŠ¤í…œ ì‹¤í–‰"""
    print(f"\n=== Running Two-Phase Stage3 System ===")
    print(f"Question ID: {test_state['current_question_id']}")
    print(f"Question Type: {test_state['question_type']}")
    print(f"Total samples: {len(test_state['stage2_texts'])}")
    
    # Phase 1 ì‹¤í–‰
    print(f"\n--- Phase 1: Primary Labeling (kNN â†’ CSLS â†’ MCL) ---")
    
    # Phase 1 ì„¤ì • ì¤€ë¹„
    phase1_config = test_state['stage3_phase1_config']
    print(f"Phase 1 config: knn_k={phase1_config['knn_k']}, mcl_inflation={phase1_config['mcl_inflation']}")
    
    phase1 = Phase1PrimaryLabeling(config=phase1_config)
    
    # ì„ë² ë”©ê³¼ í…ìŠ¤íŠ¸ ë°ì´í„° ì¶”ì¶œ
    embeddings = test_state['stage2_embeddings']
    texts = test_state['stage2_texts']
    
    print(f"Embeddings shape: {embeddings.shape}")
    print(f"Sample embeddings norm: {np.linalg.norm(embeddings[0]):.4f}")
    
    # ì§ì ‘ embeddings ë°°ì—´ì„ ì „ë‹¬
    phase1_raw_result = phase1.process_embeddings(embeddings, texts)
    
    print(f"Phase 1 raw result keys: {list(phase1_raw_result.keys())}")
    
    # ê²°ê³¼ë¥¼ state í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    phase1_result = dict(test_state)
    
    if 'error' in phase1_raw_result:
        phase1_result['error'] = phase1_raw_result['error']
        print(f"âŒ Phase 1 failed: {phase1_raw_result['error']}")
        return phase1_result
    
    # Phase 1 ê²°ê³¼ë¥¼ stateì— ì¶”ê°€
    for key, value in phase1_raw_result.items():
        phase1_result[key] = value  # stage3_phase1_ ì ‘ë‘ì‚¬ ì—†ì´ë„ ëª¨ë“  í‚¤ ì¶”ê°€
    
    print(f"âœ… Phase 1 completed successfully")
    
    # ì‹¤ì œ í‚¤ëª… ë§¤í•‘
    n_clusters = phase1_raw_result.get('n_clusters', 0)
    n_singletons = phase1_raw_result.get('n_singletons', 0)
    cluster_labels = phase1_raw_result.get('cluster_labels', [])
    prototypes = phase1_raw_result.get('prototypes', {})
    
    # í‘œì¤€ í‚¤ëª…ìœ¼ë¡œ ë§¤í•‘í•˜ì—¬ ì €ì¥
    phase1_result['stage3_phase1_num_clusters'] = n_clusters
    phase1_result['stage3_phase1_num_singletons'] = n_singletons
    phase1_result['stage3_phase1_labels'] = cluster_labels
    phase1_result['stage3_phase1_prototypes'] = prototypes
    phase1_result['stage3_phase1_metadata'] = phase1_raw_result.get('metadata', {})
    phase1_result['stage3_phase1_quality'] = phase1_raw_result.get('quality_stats', {}).get('overall_score', 0.0)
    
    print(f"Primary clusters: {n_clusters}")
    print(f"Singletons: {n_singletons}")
    print(f"Total labeled samples: {len([l for l in cluster_labels if l >= 0])}")
    print(f"Available result keys: {list(phase1_raw_result.keys())}")
    
    # Phase 2 ì‹¤í–‰
    print(f"\n--- Phase 2: Secondary Labeling (Community Detection) ---")
    
    # Phase 1 ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
    if 'stage3_phase1_labels' not in phase1_result or phase1_result.get('stage3_phase1_num_clusters', 0) == 0:
        print("âš ï¸  No Phase 1 results found, skipping Phase 2")
        return phase1_result
    
    print(f"Phase 1 clusters available: {phase1_result.get('stage3_phase1_num_clusters', 0)}")
    
    # Phase 1 ê²°ê³¼ê°€ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ Phase 2 ìƒëµ
    if phase1_result.get('stage3_phase1_num_clusters', 0) < 2:
        print("âš ï¸  Not enough clusters for Phase 2, returning Phase 1 results")
        return phase1_result
    
    phase2 = Phase2SecondaryLabeling()
    
    # Phase 2 ì…ë ¥ ë°ì´í„° ì¤€ë¹„
    cluster_labels = phase1_result['stage3_phase1_labels']
    prototypes = phase1_result['stage3_phase1_prototypes']
    metadata = phase1_result['stage3_phase1_metadata']
    
    # í´ëŸ¬ìŠ¤í„°ë³„ë¡œ ë°ì´í„° ì •ë¦¬
    unique_labels = list(set([l for l in cluster_labels if l >= 0]))
    print(f"Unique cluster labels: {len(unique_labels)} (first 10: {unique_labels[:10]})")
    
    # Phase 1 ê²°ê³¼ë¥¼ Phase 2 í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    phase1_groups = {
        'cluster_labels': cluster_labels,
        'unique_labels': unique_labels,
        'embeddings': embeddings,
        'texts': texts,
        'n_clusters': len(unique_labels)
    }
    
    try:
        phase2_raw_result = phase2.process_phase1_groups(
            phase1_groups, prototypes, metadata
        )
        
        # ê²°ê³¼ë¥¼ state í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        phase2_result = dict(phase1_result)
        
        if 'error' in phase2_raw_result:
            phase2_result['error'] = phase2_raw_result['error']
            print(f"âŒ Phase 2 failed: {phase2_raw_result['error']}")
            return phase2_result
        
        # Phase 2 ê²°ê³¼ë¥¼ stateì— ì¶”ê°€
        for key, value in phase2_raw_result.items():
            if key.startswith('stage3_phase2_'):
                phase2_result[key] = value
                
    except Exception as e:
        print(f"âš ï¸  Phase 2 processing failed: {e}")
        print("Continuing with Phase 1 results only")
        
        # Phase 1ë§Œì˜ ê²°ê³¼ë¡œ ìµœì¢… ê²°ê³¼ ì¤€ë¹„
        phase2_result = dict(phase1_result)
        
        # Phase 2 ê²°ê³¼ë¥¼ Phase 1ê³¼ ë™ì¼í•˜ê²Œ ì„¤ì • (ì˜ë¯¸ì ìœ¼ë¡œ Phase 1 í´ëŸ¬ìŠ¤í„°ê°€ ìµœì¢… ì»¤ë®¤ë‹ˆí‹°)
        phase2_result['stage3_phase2_num_communities'] = phase2_result['stage3_phase1_num_clusters']
        phase2_result['stage3_phase2_community_labels'] = phase2_result['stage3_phase1_labels']
        phase2_result['stage3_phase2_community_prototypes'] = phase2_result['stage3_phase1_prototypes']
        phase2_result['stage3_phase2_quality'] = phase2_result['stage3_phase1_quality']
        
        return phase2_result
    
    if 'error' in phase2_result:
        print(f"âŒ Phase 2 failed: {phase2_result['error']}")
        return phase2_result
    
    print(f"âœ… Phase 2 completed successfully")
    print(f"Final communities: {phase2_result.get('stage3_phase2_num_communities', 0)}")
    
    # Quality Assessment
    print(f"\n--- Quality Assessment ---")
    qa_tools = QualityAssessmentTools()
    quality_result = qa_tools.assess_two_phase_quality(phase2_result)
    
    print(f"Overall quality: {quality_result.get('overall_quality', 0):.3f}")
    print(f"Phase 1 quality: {quality_result.get('phase1_quality', 0):.3f}")
    print(f"Phase 2 quality: {quality_result.get('phase2_quality', 0):.3f}")
    
    return phase2_result

def display_results(result: Dict[str, Any]):
    """ê²°ê³¼ ìƒì„¸ ì¶œë ¥"""
    print(f"\n=== Two-Phase Results Summary ===")
    
    # ê¸°ë³¸ ì •ë³´
    print(f"Question ID: {result.get('current_question_id', 'Unknown')}")
    print(f"Question Type: {result.get('question_type', 'Unknown')}")
    print(f"Total samples: {len(result.get('stage2_texts', []))}")
    
    # Phase 1 ê²°ê³¼
    print(f"\nğŸ“Š Phase 1 Results:")
    print(f"  Primary clusters: {result.get('stage3_phase1_num_clusters', 0)}")
    print(f"  Singletons: {result.get('stage3_phase1_num_singletons', 0)}")
    print(f"  Quality score: {result.get('stage3_phase1_quality', 0):.3f}")
    
    # Phase 2 ê²°ê³¼
    print(f"\nğŸ”— Phase 2 Results:")
    print(f"  Final communities: {result.get('stage3_phase2_num_communities', 0)}")
    print(f"  Quality score: {result.get('stage3_phase2_quality', 0):.3f}")
    
    # í”„ë¡œí† íƒ€ì… ìƒì„± ê²°ê³¼
    prototypes = result.get('stage3_phase1_prototypes', {})
    if prototypes:
        print(f"\nğŸ·ï¸  Generated Prototypes (Phase 1):")
        for cluster_id, prototype in list(prototypes.items())[:5]:  # ì²« 5ê°œë§Œ í‘œì‹œ
            print(f"  Cluster {cluster_id}: {prototype}")
        if len(prototypes) > 5:
            print(f"  ... and {len(prototypes) - 5} more clusters")
    
    # ì»¤ë®¤ë‹ˆí‹° í”„ë¡œí† íƒ€ì…
    phase2_prototypes = result.get('stage3_phase2_community_prototypes', {})
    if phase2_prototypes:
        print(f"\nğŸŒ Community Prototypes (Phase 2):")
        for comm_id, prototype in list(phase2_prototypes.items())[:3]:  # ì²« 3ê°œë§Œ í‘œì‹œ
            print(f"  Community {comm_id}: {prototype}")
        if len(phase2_prototypes) > 3:
            print(f"  ... and {len(phase2_prototypes) - 3} more communities")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ Stage3 Two-Phase System - Real Data Test")
    print("=" * 60)
    
    # State íŒŒì¼ ê²½ë¡œ
    state_file_path = "/home/cyyoon/test_area/ai_text_classification/2.langgraph/data/test/state_history/20250918_113231_081_STAGE2_WORD_ë¬¸23_COMPLETED_state.json"
    
    try:
        # 1. State íŒŒì¼ ë¡œë“œ
        state_data = load_state_file(state_file_path)
        
        # 2. ì‚¬ìš© ê°€ëŠ¥í•œ ì§ˆë¬¸ë“¤ í™•ì¸
        matched_questions = state_data.get('matched_questions', {})
        available_questions = []
        
        for q_id, q_data in matched_questions.items():
            if q_data.get('stage2_data') and q_data['stage2_data'].get('csv_path'):
                csv_path = q_data['stage2_data']['csv_path']
                if os.path.exists(csv_path):
                    available_questions.append(q_id)
        
        print(f"\nğŸ“‹ Available questions with stage2 data: {available_questions}")
        
        # 3. ì²« ë²ˆì§¸ ì‚¬ìš© ê°€ëŠ¥í•œ ì§ˆë¬¸ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
        if not available_questions:
            print("âŒ No questions with valid stage2 data found")
            return
        
        # ë¬¸4 ë°ì´í„°ê°€ ìˆëŠ”ì§€ ìš°ì„  í™•ì¸
        test_question = 'ë¬¸4' if 'ë¬¸4' in available_questions else available_questions[0]
        print(f"\nğŸ¯ Testing with question: {test_question}")
        
        # 4. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
        test_state = prepare_test_data(state_data, test_question)
        
        if not test_state:
            print("âŒ Failed to prepare test data")
            return
        
        # 5. Two-phase ì‹œìŠ¤í…œ ì‹¤í–‰
        result = run_two_phase_test(test_state)
        
        if 'error' in result:
            print(f"âŒ Test failed: {result['error']}")
            return
        
        # 6. ê²°ê³¼ ì¶œë ¥
        display_results(result)
        
        print(f"\nâœ… Real data test completed successfully!")
        
    except Exception as e:
        print(f"âŒ Error during real data test: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()