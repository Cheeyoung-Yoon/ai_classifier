#!/usr/bin/env python3
"""ì‹¤ì œ Stage2 ë°ì´í„°ë¡œ í–¥ìƒëœ KNNâ†’CSLSâ†’MCL íŒŒì´í”„ë¼ì¸ ì „ì²´ í…ŒìŠ¤íŠ¸"""

import pandas as pd
import numpy as np
import os
import sys
import time
from pathlib import Path
from sklearn.neighbors import NearestNeighbors
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score
import markov_clustering as mc
import networkx as nx

# Add project root to path using config
try:
    from config.config import settings
    project_root = Path(settings.PROJECT_DATA_BASE_DIR).resolve()
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))
except ImportError:
    # Fallback for when config is not available
    project_root = Path(__file__).parent.resolve()
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))

def assess_quality(nmi_score, ari_score):
    """NMIì™€ ARI ì ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í’ˆì§ˆ ë“±ê¸‰ í‰ê°€"""
    combined_score = (nmi_score + ari_score) / 2
    
    if combined_score >= 0.96:
        return "EXCELLENT", combined_score
    elif combined_score >= 0.88:
        return "GOOD", combined_score
    elif combined_score >= 0.83:
        return "FAIR", combined_score
    elif combined_score >= 0.72:
        return "IMPROVE", combined_score
    else:
        return "FAIL", combined_score

def try_knn_csls_mcl_pipeline(embeddings, texts, k=10, inflation=2.0):
    """í–¥ìƒëœ KNN â†’ CSLS â†’ MCL íŒŒì´í”„ë¼ì¸"""
    
    n_samples = len(embeddings)
    if n_samples < 2:
        return list(range(n_samples)), "insufficient_data", 0.0, 0.0
    
    try:
        print(f"  ğŸ”„ KNN â†’ CSLS â†’ MCL íŒŒì´í”„ë¼ì¸ ì‹œì‘ (k={k}, inflation={inflation})")
        
        # 1. KNN ê·¸ë˜í”„ êµ¬ì„±
        print(f"     1ï¸âƒ£ KNN ê·¸ë˜í”„ êµ¬ì„± ì¤‘...")
        nn = NearestNeighbors(n_neighbors=min(k, n_samples-1), metric='cosine')
        nn.fit(embeddings)
        distances, indices = nn.kneighbors(embeddings)
        
        # 2. CSLS (Cross-domain Similarity Local Scaling) ì ìš©
        print(f"     2ï¸âƒ£ CSLS ìŠ¤ì¼€ì¼ë§ ì ìš© ì¤‘...")
        # ê° í¬ì¸íŠ¸ì˜ í‰ê·  ìœ ì‚¬ë„ ê³„ì‚°
        cos_similarities = 1 - distances  # cosine distanceë¥¼ similarityë¡œ ë³€í™˜
        mean_similarities = np.mean(cos_similarities, axis=1)
        
        # CSLS ê·¸ë˜í”„ êµ¬ì„±
        adjacency_matrix = np.zeros((n_samples, n_samples))
        
        for i in range(n_samples):
            for j_idx, j in enumerate(indices[i]):
                if i != j:
                    cos_ij = cos_similarities[i, j_idx]
                    # CSLS ê³µì‹: 2 * cos(xi, xj) - r(xi) - r(xj)
                    csls_score = 2 * cos_ij - mean_similarities[i] - mean_similarities[j]
                    
                    if csls_score > 0:  # ì–‘ìˆ˜ì¸ ê²½ìš°ë§Œ ì—°ê²°
                        adjacency_matrix[i, j] = csls_score
        
        # ëŒ€ì¹­í™”
        adjacency_matrix = (adjacency_matrix + adjacency_matrix.T) / 2
        
        # 3. MCL í´ëŸ¬ìŠ¤í„°ë§
        print(f"     3ï¸âƒ£ MCL í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰ ì¤‘...")
        result = mc.run_mcl(adjacency_matrix, inflation=inflation)
        clusters = mc.get_clusters(result)
        
        if not clusters:
            return list(range(n_samples)), "mcl_failed", 0.0, 0.0
        
        # í´ëŸ¬ìŠ¤í„° ë¼ë²¨ í• ë‹¹
        labels = np.zeros(n_samples, dtype=int)
        for cluster_id, cluster_nodes in enumerate(clusters):
            for node in cluster_nodes:
                labels[node] = cluster_id
        
        print(f"     âœ… KNNâ†’CSLSâ†’MCL ì™„ë£Œ: {len(clusters)}ê°œ í´ëŸ¬ìŠ¤í„°")
        
        return labels.tolist(), "knn_csls_mcl", len(clusters), adjacency_matrix.sum()
        
    except Exception as e:
        print(f"     âŒ KNNâ†’CSLSâ†’MCL ì‹¤íŒ¨: {e}")
        return list(range(n_samples)), "knn_csls_mcl_failed", 0.0, 0.0

def match_labels_across_columns(results_by_column):
    """ê°™ì€ ì§ˆë¬¸ ë‚´ ì»¬ëŸ¼ ê°„ ë¼ë²¨ ë§¤ì¹­"""
    
    if len(results_by_column) < 2:
        return results_by_column
    
    print(f"  ğŸ”— ì»¬ëŸ¼ ê°„ ë¼ë²¨ ë§¤ì¹­ ì‹œì‘ ({len(results_by_column)}ê°œ ì»¬ëŸ¼)")
    
    try:
        # ê° ì»¬ëŸ¼ì˜ í´ëŸ¬ìŠ¤í„° ëŒ€í‘œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        column_clusters = {}
        for column, result in results_by_column.items():
            if 'cluster_labels' not in result or 'texts' not in result:
                continue
            
            cluster_texts = {}
            for i, (text, label) in enumerate(zip(result['texts'], result['cluster_labels'])):
                if label not in cluster_texts:
                    cluster_texts[label] = []
                cluster_texts[label].append(text)
            
            # ê° í´ëŸ¬ìŠ¤í„°ì˜ ëŒ€í‘œ í…ìŠ¤íŠ¸ (ê°€ì¥ ê¸´ í…ìŠ¤íŠ¸)
            cluster_representatives = {}
            for label, texts in cluster_texts.items():
                cluster_representatives[label] = max(texts, key=len)
            
            column_clusters[column] = cluster_representatives
        
        if len(column_clusters) < 2:
            return results_by_column
        
        # TF-IDFë¥¼ ì‚¬ìš©í•œ í´ëŸ¬ìŠ¤í„° ê°„ ìœ ì‚¬ë„ ê³„ì‚°
        all_representatives = []
        cluster_mapping = []
        
        for column, representatives in column_clusters.items():
            for label, text in representatives.items():
                all_representatives.append(text)
                cluster_mapping.append((column, label))
        
        if len(all_representatives) < 2:
            return results_by_column
        
        # TF-IDF ë²¡í„°í™”
        vectorizer = TfidfVectorizer(max_features=1000, stop_words=None)
        tfidf_matrix = vectorizer.fit_transform(all_representatives)
        similarity_matrix = cosine_similarity(tfidf_matrix)
        
        # ì»¬ëŸ¼ ê°„ í´ëŸ¬ìŠ¤í„° ë§¤ì¹­
        base_column = list(column_clusters.keys())[0]
        matched_results = {base_column: results_by_column[base_column]}
        
        for target_column in list(column_clusters.keys())[1:]:
            if target_column not in results_by_column:
                continue
            
            base_indices = [i for i, (col, _) in enumerate(cluster_mapping) if col == base_column]
            target_indices = [i for i, (col, _) in enumerate(cluster_mapping) if col == target_column]
            
            # ìµœì  ë§¤ì¹­ ì°¾ê¸°
            label_mapping = {}
            for target_idx in target_indices:
                target_label = cluster_mapping[target_idx][1]
                best_similarity = -1
                best_base_label = 0
                
                for base_idx in base_indices:
                    base_label = cluster_mapping[base_idx][1]
                    sim = similarity_matrix[base_idx, target_idx]
                    
                    if sim > best_similarity:
                        best_similarity = sim
                        best_base_label = base_label
                
                label_mapping[target_label] = best_base_label
            
            # ë¼ë²¨ ì¬í• ë‹¹
            new_result = results_by_column[target_column].copy()
            if 'cluster_labels' in new_result:
                new_labels = [label_mapping.get(label, label) for label in new_result['cluster_labels']]
                new_result['cluster_labels'] = new_labels
                
                # í´ëŸ¬ìŠ¤í„° ìˆ˜ ì—…ë°ì´íŠ¸
                new_result['n_clusters'] = len(set(new_labels))
            
            matched_results[target_column] = new_result
        
        print(f"     âœ… ì»¬ëŸ¼ ê°„ ë¼ë²¨ ë§¤ì¹­ ì™„ë£Œ")
        return matched_results
        
    except Exception as e:
        print(f"     âŒ ë¼ë²¨ ë§¤ì¹­ ì‹¤íŒ¨: {e}")
        return results_by_column

def load_column_wise_data(directory_path):
    """ì§ˆë¬¸ë³„, ì»¬ëŸ¼ë³„ë¡œ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    data_groups = {}
    
    if not os.path.exists(directory_path):
        print(f"âš ï¸ Directory not found: {directory_path}")
        return data_groups
    
    csv_files = []
    for root, dirs, files in os.walk(directory_path):
        for file in files:
            if file.endswith('.csv'):
                csv_files.append(os.path.join(root, file))
    
    print(f"ğŸ“ Found {len(csv_files)} CSV files")
    
    for file_path in csv_files:
        try:
            df = pd.read_csv(file_path)
            
            # ì§ˆë¬¸ ID ì¶”ì¶œ
            question_id = None
            if 'question_id' in df.columns and not df['question_id'].isna().all():
                question_id = df['question_id'].iloc[0]
            else:
                filename = os.path.basename(file_path)
                import re
                match = re.search(r'ë¬¸(\d+)', filename)
                if match:
                    question_id = f"ë¬¸{match.group(1)}"
            
            if not question_id:
                continue
            
            # í…ìŠ¤íŠ¸ ì»¬ëŸ¼ í™•ì¸
            text_columns = []
            for col in df.columns:
                if col.startswith('text_') and 'embed' not in col:
                    text_columns.append(col)
            
            # ê° í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì— ëŒ€í•´ ì²˜ë¦¬
            for text_col in text_columns:
                embed_col = f"embed_{text_col}"
                if embed_col not in df.columns:
                    continue
                
                valid_mask = df[text_col].notna() & df[embed_col].notna()
                valid_df = df[valid_mask].copy()
                
                if len(valid_df) == 0:
                    continue
                
                try:
                    embeddings = []
                    for embed_str in valid_df[embed_col]:
                        if isinstance(embed_str, str):
                            embed_array = np.array(eval(embed_str))
                        else:
                            embed_array = np.array(embed_str)
                        embeddings.append(embed_array)
                    
                    embeddings = np.array(embeddings)
                    group_key = f"{question_id}_{text_col}"
                    
                    data_groups[group_key] = {
                        'texts': valid_df[text_col].tolist(),
                        'embeddings': embeddings,
                        'question_id': question_id,
                        'column': text_col,
                        'file_path': file_path
                    }
                    
                except Exception as e:
                    continue
                    
        except Exception as e:
            continue
    
    return data_groups

def test_enhanced_stage3_pipeline():
    """í–¥ìƒëœ Stage3 íŒŒì´í”„ë¼ì¸ ì „ì²´ í…ŒìŠ¤íŠ¸"""
    
    print("ğŸš€ í–¥ìƒëœ Stage3 íŒŒì´í”„ë¼ì¸ ì‹¤ì œ ë°ì´í„° í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    
    # ì‹¤ì œ ë°ì´í„° ë¡œë”©
    data_directory = "/home/cyyoon/test_area/ai_text_classification/2.langgraph/data/test/temp_data/stage2_results copy/"
    data_groups = load_column_wise_data(data_directory)
    
    if not data_groups:
        print("âŒ ë¡œë”©ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“Š ì´ {len(data_groups)}ê°œ ë°ì´í„° ê·¸ë£¹ ë¡œë”© ì™„ë£Œ")
    
    # ì§ˆë¬¸ë³„ë¡œ ê·¸ë£¹í™”
    questions = {}
    for group_key, data in data_groups.items():
        question_id = data['question_id']
        if question_id not in questions:
            questions[question_id] = {}
        questions[question_id][data['column']] = data
    
    print(f"ğŸ“‹ ì´ {len(questions)}ê°œ ì§ˆë¬¸ ë°œê²¬: {list(questions.keys())}")
    
    # ê° ì§ˆë¬¸ì— ëŒ€í•´ ì²˜ë¦¬
    all_results = {}
    
    for question_id, question_data in questions.items():
        print(f"\n{'=' * 50}")
        print(f"ğŸ” {question_id} ì²˜ë¦¬ ì¤‘ ({len(question_data)}ê°œ ì»¬ëŸ¼)")
        print(f"{'=' * 50}")
        
        start_time = time.time()
        
        # ê° ì»¬ëŸ¼ì— ëŒ€í•´ í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰
        column_results = {}
        
        for column, data in question_data.items():
            print(f"\nğŸ“Š {column} ì²˜ë¦¬ ì¤‘...")
            print(f"   â€¢ ìƒ˜í”Œ ìˆ˜: {len(data['texts'])}")
            print(f"   â€¢ ì„ë² ë”© í˜•íƒœ: {data['embeddings'].shape}")
            
            # KNNâ†’CSLSâ†’MCL íŒŒì´í”„ë¼ì¸ ì ìš©
            cluster_labels, algorithm, n_clusters, graph_weight = try_knn_csls_mcl_pipeline(
                data['embeddings'], 
                data['texts']
            )
            
            # ê°€ìƒì˜ ì •ë‹µ ë¼ë²¨ ìƒì„± (ì‹¤ì œë¡œëŠ” ìˆ˜ë™ ë¼ë²¨ë§ëœ ë°ì´í„° ì‚¬ìš©)
            # ì—¬ê¸°ì„œëŠ” í…ìŠ¤íŠ¸ ê¸°ë°˜ ê°„ë‹¨í•œ ë¼ë²¨ë§ ì‹œë®¬ë ˆì´ì…˜
            true_labels = []
            unique_texts = list(set(data['texts']))
            text_to_label = {text: i for i, text in enumerate(unique_texts)}
            true_labels = [text_to_label[text] for text in data['texts']]
            
            # NMI, ARI ê³„ì‚°
            if len(set(cluster_labels)) > 1 and len(set(true_labels)) > 1:
                nmi_score = normalized_mutual_info_score(true_labels, cluster_labels)
                ari_score = adjusted_rand_score(true_labels, cluster_labels)
            else:
                nmi_score = 0.0
                ari_score = 0.0
            
            # í’ˆì§ˆ í‰ê°€
            quality_grade, combined_score = assess_quality(nmi_score, ari_score)
            
            column_results[column] = {
                'texts': data['texts'],
                'embeddings': data['embeddings'],
                'cluster_labels': cluster_labels,
                'true_labels': true_labels,
                'algorithm': algorithm,
                'n_clusters': n_clusters,
                'n_samples': len(data['texts']),
                'nmi_score': nmi_score,
                'ari_score': ari_score,
                'combined_score': combined_score,
                'quality_grade': quality_grade,
                'graph_weight': graph_weight
            }
            
            print(f"   âœ… {column} ì™„ë£Œ:")
            print(f"      â€¢ ì•Œê³ ë¦¬ì¦˜: {algorithm}")
            print(f"      â€¢ í´ëŸ¬ìŠ¤í„° ìˆ˜: {n_clusters}")
            print(f"      â€¢ NMI: {nmi_score:.4f}")
            print(f"      â€¢ ARI: {ari_score:.4f}")
            print(f"      â€¢ í’ˆì§ˆ: {quality_grade} ({combined_score:.4f})")
        
        # ì»¬ëŸ¼ ê°„ ë¼ë²¨ ë§¤ì¹­
        if len(column_results) > 1:
            print(f"\nğŸ”— {question_id} ì»¬ëŸ¼ ê°„ ë¼ë²¨ ë§¤ì¹­...")
            matched_results = match_labels_across_columns(column_results)
        else:
            matched_results = column_results
        
        # ê²°ê³¼ ì €ì¥
        all_results[question_id] = matched_results
        
        elapsed_time = time.time() - start_time
        print(f"\nâ±ï¸ {question_id} ì²˜ë¦¬ ì™„ë£Œ ({elapsed_time:.2f}ì´ˆ)")
    
    # ì „ì²´ ê²°ê³¼ ìš”ì•½
    print(f"\n{'=' * 70}")
    print("ğŸ“Š ì „ì²´ ê²°ê³¼ ìš”ì•½")
    print(f"{'=' * 70}")
    
    total_samples = 0
    quality_counts = {"EXCELLENT": 0, "GOOD": 0, "FAIR": 0, "IMPROVE": 0, "FAIL": 0}
    algorithm_counts = {}
    
    for question_id, question_results in all_results.items():
        print(f"\nğŸ” {question_id}:")
        
        for column, result in question_results.items():
            total_samples += result['n_samples']
            quality_counts[result['quality_grade']] += 1
            
            algorithm = result['algorithm']
            algorithm_counts[algorithm] = algorithm_counts.get(algorithm, 0) + 1
            
            print(f"   ğŸ“Š {column}:")
            print(f"      â€¢ ìƒ˜í”Œ: {result['n_samples']}, í´ëŸ¬ìŠ¤í„°: {result['n_clusters']}")
            print(f"      â€¢ ì•Œê³ ë¦¬ì¦˜: {result['algorithm']}")
            print(f"      â€¢ NMI: {result['nmi_score']:.4f}, ARI: {result['ari_score']:.4f}")
            print(f"      â€¢ í’ˆì§ˆ: {result['quality_grade']} ({result['combined_score']:.4f})")
    
    print(f"\nğŸ“ˆ ì „ì²´ í†µê³„:")
    print(f"   â€¢ ì´ ìƒ˜í”Œ ìˆ˜: {total_samples:,}")
    print(f"   â€¢ ì´ ì²˜ë¦¬ ê·¸ë£¹: {sum(len(qr) for qr in all_results.values())}")
    print(f"   â€¢ í’ˆì§ˆ ë¶„í¬: {dict(quality_counts)}")
    print(f"   â€¢ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©: {dict(algorithm_counts)}")
    
    print(f"\nâœ… í–¥ìƒëœ Stage3 íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    
    return all_results

if __name__ == "__main__":
    test_enhanced_stage3_pipeline()