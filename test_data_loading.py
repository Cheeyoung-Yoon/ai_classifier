#!/usr/bin/env python3
"""ì‹¤ì œ Stage2 ë°ì´í„°ë¡œ í–¥ìƒëœ Stage3 íŒŒì´í”„ë¼ì¸ ì§ì ‘ í…ŒìŠ¤íŠ¸"""

import pandas as pd
import numpy as np
import os
import sys
sys.path.append('/home/cyyoon/test_area/ai_text_classification/2.langgraph')

def load_column_wise_data(directory_path):
    """ì§ˆë¬¸ë³„, ì»¬ëŸ¼ë³„ë¡œ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    data_groups = {}
    
    # ëª¨ë“  CSV íŒŒì¼ ì°¾ê¸°
    if not os.path.exists(directory_path):
        print(f"âš ï¸ Directory not found: {directory_path}")
        return data_groups
    
    csv_files = []
    for root, dirs, files in os.walk(directory_path):
        for file in files:
            if file.endswith('.csv'):
                csv_files.append(os.path.join(root, file))
    
    if not csv_files:
        print(f"âš ï¸ No CSV files found in {directory_path}")
        return data_groups
    
    print(f"ğŸ“ Found {len(csv_files)} CSV files")
    
    for file_path in csv_files:
        try:
            df = pd.read_csv(file_path)
            print(f"ğŸ“„ Processing {os.path.basename(file_path)}: {len(df)} rows")
            print(f"   Columns: {list(df.columns)}")
            
            # ì§ˆë¬¸ ID ì¶”ì¶œ (íŒŒì¼ëª… ë˜ëŠ” question_id ì»¬ëŸ¼ì—ì„œ)
            question_id = None
            if 'question_id' in df.columns and not df['question_id'].isna().all():
                question_id = df['question_id'].iloc[0]
            else:
                # íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ (ì˜ˆ: stage2_ë¬¸4_img_20250917_154740.csv -> ë¬¸4)
                filename = os.path.basename(file_path)
                import re
                match = re.search(r'ë¬¸(\d+)', filename)
                if match:
                    question_id = f"ë¬¸{match.group(1)}"
            
            if not question_id:
                print(f"   âš ï¸ Could not extract question_id from {file_path}")
                continue
            
            # í…ìŠ¤íŠ¸ ì»¬ëŸ¼ í™•ì¸ - ì •í™•í•œ íŒ¨í„´ ë§¤ì¹­
            text_columns = []
            for col in df.columns:
                # text_1, text_2 ë“±ì˜ íŒ¨í„´ë§Œ ë§¤ì¹­ (embedê°€ í¬í•¨ëœ ê²ƒì€ ì œì™¸)
                if col.startswith('text_') and 'embed' not in col:
                    text_columns.append(col)
            
            if not text_columns:
                print(f"   âš ï¸ No text columns found in {file_path}")
                print(f"   Available columns: {list(df.columns)}")
                continue
            
            # ê° í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì— ëŒ€í•´ ì²˜ë¦¬
            for text_col in text_columns:
                # í•´ë‹¹í•˜ëŠ” ì„ë² ë”© ì»¬ëŸ¼ ì°¾ê¸°
                embed_col = f"embed_{text_col}"
                if embed_col not in df.columns:
                    print(f"   âš ï¸ No embedding column {embed_col} found for {text_col}")
                    continue
                
                # ìœ íš¨í•œ ë°ì´í„°ë§Œ í•„í„°ë§
                valid_mask = df[text_col].notna() & df[embed_col].notna()
                valid_df = df[valid_mask].copy()
                
                if len(valid_df) == 0:
                    print(f"   âš ï¸ No valid data for {text_col}")
                    continue
                
                # ì„ë² ë”© ë¬¸ìì—´ì„ numpy ë°°ì—´ë¡œ ë³€í™˜
                try:
                    embeddings = []
                    for embed_str in valid_df[embed_col]:
                        if isinstance(embed_str, str):
                            embed_array = np.array(eval(embed_str))
                        else:
                            embed_array = np.array(embed_str)
                        embeddings.append(embed_array)
                    
                    embeddings = np.array(embeddings)
                    
                    # ê·¸ë£¹ í‚¤ ìƒì„±
                    group_key = f"{question_id}_{text_col}"
                    
                    data_groups[group_key] = {
                        'texts': valid_df[text_col].tolist(),
                        'embeddings': embeddings,
                        'question_id': question_id,
                        'column': text_col,
                        'file_path': file_path
                    }
                    
                    print(f"   âœ… Loaded {len(valid_df)} samples for {group_key}")
                    print(f"   ğŸ“ Embedding shape: {embeddings.shape}")
                    
                except Exception as e:
                    print(f"   âŒ Error processing embeddings for {text_col}: {e}")
                    continue
                    
        except Exception as e:
            print(f"âŒ Error processing {file_path}: {e}")
            continue
    
    print(f"\nğŸ“Š Total data groups loaded: {len(data_groups)}")
    return data_groups

def test_data_loading():
    """ì‹¤ì œ Stage2 ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸"""
    
    print("ğŸš€ ì‹¤ì œ Stage2 ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # ì‹¤ì œ Stage2 ë°ì´í„° ê²½ë¡œ
    data_directory = "/home/cyyoon/test_area/ai_text_classification/2.langgraph/data/test/temp_data/stage2_results copy/"
    
    try:
        # ë°ì´í„° ë¡œë”©
        data_groups = load_column_wise_data(data_directory)
        
        print("\n" + "=" * 60)
        print("ğŸ“Š ë¡œë”©ëœ ë°ì´í„° ìš”ì•½")
        print("=" * 60)
        
        if data_groups:
            for group_key, data in data_groups.items():
                print(f"\nğŸ” {group_key}:")
                print(f"   â€¢ í…ìŠ¤íŠ¸ ìˆ˜: {len(data['texts'])}")
                print(f"   â€¢ ì„ë² ë”© í˜•íƒœ: {data['embeddings'].shape}")
                print(f"   â€¢ ì§ˆë¬¸ ID: {data['question_id']}")
                print(f"   â€¢ ì»¬ëŸ¼: {data['column']}")
                
                # ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸ ìƒ˜í”Œ í‘œì‹œ
                if data['texts']:
                    sample_text = data['texts'][0]
                    if len(sample_text) > 50:
                        sample_text = sample_text[:50] + "..."
                    print(f"   â€¢ ìƒ˜í”Œ í…ìŠ¤íŠ¸: '{sample_text}'")
        else:
            print("âŒ ë¡œë”©ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
        print("\nâœ… ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        return data_groups
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return {}

if __name__ == "__main__":
    test_data_loading()