#!/usr/bin/env python3
"""
ê°œì„ ëœ ì„¸ë¶€ì ì¸ ê°œë³„ ë…¸ë“œ í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ (ë¬¸ì œì  ìˆ˜ì •)
"""

import os
import sys
import time
import tempfile
import shutil
import traceback
import pandas as pd
from pathlib import Path
from unittest.mock import Mock, patch, MagicMock
from typing import Dict, Any, List, Callable, Tuple
import json
from datetime import datetime

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))


class DetailedLogger:
    """ìƒì„¸í•œ ë¡œê·¸ ì¶œë ¥ì„ ìœ„í•œ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.indent_level = 0
        self.test_start_time = None
        self.node_start_time = None
        
    def log(self, message: str, level: str = "INFO"):
        """ë ˆë²¨ë³„ ë¡œê·¸ ì¶œë ¥"""
        indent = "  " * self.indent_level
        timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
        
        if level == "HEADER":
            print(f"\n{'='*80}")
            print(f"{indent}ğŸ¯ {message}")
            print(f"{'='*80}")
        elif level == "NODE":
            print(f"\n{'-'*60}")
            print(f"{indent}ğŸ”§ {message}")
            print(f"{'-'*60}")
        elif level == "TEST":
            print(f"\n{indent}ğŸ§ª {message}")
        elif level == "SUCCESS":
            print(f"{indent}âœ… {message}")
        elif level == "ERROR":
            print(f"{indent}âŒ {message}")
        elif level == "WARNING":
            print(f"{indent}âš ï¸  {message}")
        elif level == "DEBUG":
            print(f"{indent}ğŸ” [{timestamp}] {message}")
        elif level == "INFO":
            print(f"{indent}â„¹ï¸  {message}")
        elif level == "TIMER":
            print(f"{indent}â±ï¸  {message}")
        else:
            print(f"{indent}{message}")
    
    def start_timer(self, context: str = "test"):
        """íƒ€ì´ë¨¸ ì‹œì‘"""
        if context == "node":
            self.node_start_time = time.time()
        else:
            self.test_start_time = time.time()
    
    def end_timer(self, context: str = "test") -> float:
        """íƒ€ì´ë¨¸ ì¢…ë£Œ ë° ê²½ê³¼ ì‹œê°„ ë°˜í™˜"""
        if context == "node" and self.node_start_time:
            elapsed = time.time() - self.node_start_time
            self.log(f"Node execution time: {elapsed:.3f}s", "TIMER")
            return elapsed
        elif self.test_start_time:
            elapsed = time.time() - self.test_start_time
            self.log(f"Test execution time: {elapsed:.3f}s", "TIMER")
            return elapsed
        return 0.0
    
    def indent(self):
        """ì¸ë´íŠ¸ ì¦ê°€"""
        self.indent_level += 1
    
    def dedent(self):
        """ì¸ë´íŠ¸ ê°ì†Œ"""
        self.indent_level = max(0, self.indent_level - 1)


class NodeTestFixtures:
    """ë…¸ë“œ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ë°ì´í„° í”½ìŠ¤ì³"""
    
    @staticmethod
    def create_base_state() -> Dict[str, Any]:
        """ê¸°ë³¸ ìƒíƒœ ìƒì„±"""
        return {
            'project_name': 'detailed_test_project',
            'survey_file_path': '/tmp/test_survey.txt',
            'data_file_path': '/tmp/test_data.xlsx',
            'pipeline_id': 'detailed_test_pipeline_001',
            'current_stage': 'INITIALIZATION',
            'total_llm_cost_usd': 0.0,
            'questions': {},
            'data': None,
            'survey_raw_content': '',
            'survey_context': '',
            'question_data_match': {},
            'open_columns': [],
            'question_processing_queue': [],
            'current_question_idx': 0,
            'current_question': None,
            'current_data_sample': [],
            'stage2_processing_complete': False,
            'raw_dataframe_path': '/tmp/test_data.xlsx'
        }
    
    @staticmethod
    def create_survey_content() -> str:
        """í…ŒìŠ¤íŠ¸ìš© ì„¤ë¬¸ ë‚´ìš© ìƒì„±"""
        return """
Q1. ë¸Œëœë“œì— ëŒ€í•œ ì „ë°˜ì ì¸ ë§Œì¡±ë„ëŠ” ì–´ë– ì‹ ê°€ìš”?
â‘  ë§¤ìš° ë§Œì¡± â‘¡ ë§Œì¡± â‘¢ ë³´í†µ â‘£ ë¶ˆë§Œì¡± â‘¤ ë§¤ìš° ë¶ˆë§Œì¡±

Q2. ì œí’ˆ í’ˆì§ˆì— ëŒ€í•œ ì˜ê²¬ì„ ìì„¸íˆ ë§ì”€í•´ì£¼ì„¸ìš”.
(ììœ  ì„œìˆ í˜•)

Q3. ê°€ê²© ëŒ€ë¹„ ë§Œì¡±ë„ëŠ” ì–´ë– ì‹ ê°€ìš”?
â‘  ë§¤ìš° ì¢‹ìŒ â‘¡ ì¢‹ìŒ â‘¢ ë³´í†µ â‘£ ë‚˜ì¨ â‘¤ ë§¤ìš° ë‚˜ì¨

Q4. ì¶”ì²œí•˜ê³  ì‹¶ì€ ì •ë„ë¥¼ ë§ì”€í•´ì£¼ì„¸ìš”.
(ììœ  ì‘ë‹µ)
        """
    
    @staticmethod
    def create_test_dataframe_with_id() -> pd.DataFrame:
        """ID ì»¬ëŸ¼ì´ í¬í•¨ëœ í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°í”„ë ˆì„ ìƒì„±"""
        return pd.DataFrame({
            'ID': [1, 2, 3, 4, 5],  # SmartExcelLoaderê°€ ìš”êµ¬í•˜ëŠ” ID ì»¬ëŸ¼ ì¶”ê°€
            'Q1': ['ë§¤ìš° ë§Œì¡±', 'ë§Œì¡±', 'ë³´í†µ', 'ë¶ˆë§Œì¡±', 'ë§¤ìš° ë§Œì¡±'],
            'Q2': [
                'í’ˆì§ˆì´ ì •ë§ ì¢‹ì•„ìš”. ê¸°ëŒ€ ì´ìƒì…ë‹ˆë‹¤.',
                'ê´œì°®ì€ í¸ì´ì§€ë§Œ ê°œì„ í•  ì ì´ ìˆì–´ìš”.',
                'ê·¸ëƒ¥ ë³´í†µì´ì—ìš”. íŠ¹ë³„í•˜ì§€ ì•Šì•„ìš”.',
                'í’ˆì§ˆì´ ì•„ì‰¬ì›Œìš”. ë” ì¢‹ì•„ì¡Œìœ¼ë©´ í•´ìš”.',
                'í’ˆì§ˆ ìµœê³ ! ë§¤ìš° ë§Œì¡±í•©ë‹ˆë‹¤.'
            ],
            'Q3': ['ì¢‹ìŒ', 'ë³´í†µ', 'ë‚˜ì¨', 'ë³´í†µ', 'ë§¤ìš° ì¢‹ìŒ'],
            'Q4': [
                'ì ê·¹ ì¶”ì²œí•˜ê³  ì‹¶ì–´ìš”!',
                'ì§€ì¸ì—ê²Œ ì¶”ì²œí•  ì˜í–¥ ìˆì–´ìš”.',
                'ì¶”ì²œí•˜ì§€ ì•Šì„ ê²ƒ ê°™ì•„ìš”.',
                'ì˜ ëª¨ë¥´ê² ì–´ìš”.',
                'ê¼­ ì¶”ì²œí•˜ê³  ì‹¶ì–´ìš”!'
            ],
            'respondent_id': [1, 2, 3, 4, 5]
        })
    
    @staticmethod
    def create_questions_dict() -> Dict[str, Any]:
        """í…ŒìŠ¤íŠ¸ìš© ì§ˆë¬¸ ë”•ì…”ë„ˆë¦¬ ìƒì„±"""
        return {
            'Q1': {
                'question_number': 'Q1',
                'question_text': 'ë¸Œëœë“œì— ëŒ€í•œ ì „ë°˜ì ì¸ ë§Œì¡±ë„ëŠ” ì–´ë– ì‹ ê°€ìš”?',
                'question_type': 'MULTIPLE_CHOICE',
                'choices': {
                    '1': 'ë§¤ìš° ë§Œì¡±',
                    '2': 'ë§Œì¡±',
                    '3': 'ë³´í†µ',
                    '4': 'ë¶ˆë§Œì¡±',
                    '5': 'ë§¤ìš° ë¶ˆë§Œì¡±'
                }
            },
            'Q2': {
                'question_number': 'Q2',
                'question_text': 'ì œí’ˆ í’ˆì§ˆì— ëŒ€í•œ ì˜ê²¬ì„ ìì„¸íˆ ë§ì”€í•´ì£¼ì„¸ìš”.',
                'question_type': 'OPEN_ENDED',
                'choices': {}
            },
            'Q3': {
                'question_number': 'Q3',
                'question_text': 'ê°€ê²© ëŒ€ë¹„ ë§Œì¡±ë„ëŠ” ì–´ë– ì‹ ê°€ìš”?',
                'question_type': 'MULTIPLE_CHOICE',
                'choices': {
                    '1': 'ë§¤ìš° ì¢‹ìŒ',
                    '2': 'ì¢‹ìŒ',
                    '3': 'ë³´í†µ',
                    '4': 'ë‚˜ì¨',
                    '5': 'ë§¤ìš° ë‚˜ì¨'
                }
            },
            'Q4': {
                'question_number': 'Q4',
                'question_text': 'ì¶”ì²œí•˜ê³  ì‹¶ì€ ì •ë„ë¥¼ ë§ì”€í•´ì£¼ì„¸ìš”.',
                'question_type': 'OPEN_ENDED',
                'choices': {}
            }
        }


class ImprovedNodeTester:
    """ê°œì„ ëœ ê°œë³„ ë…¸ë“œ í…ŒìŠ¤í„°"""
    
    def __init__(self):
        self.logger = DetailedLogger()
        self.fixtures = NodeTestFixtures()
        self.temp_dir = None
        self.project_dir = None
        self.test_results = {}
        
    def setup_test_environment(self):
        """í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì • - í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë„ ìƒì„±"""
        self.logger.log("í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì • ì¤‘...", "INFO")
        self.temp_dir = tempfile.mkdtemp()
        
        # í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
        self.project_dir = Path(project_root) / "data" / "detailed_test_project"
        self.project_dir.mkdir(parents=True, exist_ok=True)
        
        # í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
        survey_file = Path(self.temp_dir) / "test_survey.txt"
        data_file = Path(self.temp_dir) / "test_data.xlsx"
        
        survey_file.write_text(self.fixtures.create_survey_content(), encoding='utf-8')
        
        # ID ì»¬ëŸ¼ì´ í¬í•¨ëœ Excel íŒŒì¼ë¡œ ì €ì¥
        df = self.fixtures.create_test_dataframe_with_id()
        df.to_excel(data_file, index=False, engine='openpyxl')
        
        self.logger.log(f"ì„ì‹œ ë””ë ‰í† ë¦¬: {self.temp_dir}", "DEBUG")
        self.logger.log(f"í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬: {self.project_dir}", "DEBUG")
        self.logger.log(f"ì„¤ë¬¸ íŒŒì¼: {survey_file}", "DEBUG")
        self.logger.log(f"ë°ì´í„° íŒŒì¼: {data_file}", "DEBUG")
        
        return str(survey_file), str(data_file)
    
    def cleanup_test_environment(self):
        """í…ŒìŠ¤íŠ¸ í™˜ê²½ ì •ë¦¬"""
        if self.temp_dir:
            shutil.rmtree(self.temp_dir, ignore_errors=True)
            self.logger.log("ì„ì‹œ í…ŒìŠ¤íŠ¸ í™˜ê²½ ì •ë¦¬ ì™„ë£Œ", "INFO")
        
        if self.project_dir:
            shutil.rmtree(self.project_dir, ignore_errors=True)
            self.logger.log("í”„ë¡œì íŠ¸ í…ŒìŠ¤íŠ¸ í™˜ê²½ ì •ë¦¬ ì™„ë£Œ", "INFO")
    
    def safe_compare_values(self, old_val, new_val, key: str) -> bool:
        """DataFrame ë“±ì„ ì•ˆì „í•˜ê²Œ ë¹„êµ"""
        try:
            if isinstance(old_val, pd.DataFrame) and isinstance(new_val, pd.DataFrame):
                return old_val.equals(new_val)
            elif isinstance(old_val, pd.DataFrame) or isinstance(new_val, pd.DataFrame):
                return False  # í•˜ë‚˜ë§Œ DataFrameì¸ ê²½ìš°
            else:
                return old_val != new_val
        except (ValueError, TypeError):
            # ë¹„êµí•  ìˆ˜ ì—†ëŠ” íƒ€ì…ë“¤ì€ ë³€ê²½ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
            return True
    
    def test_single_node(self, node_name: str, node_function: Callable, 
                        input_state: Dict[str, Any], 
                        test_description: str = "") -> Tuple[bool, Dict[str, Any], str]:
        """ë‹¨ì¼ ë…¸ë“œ í…ŒìŠ¤íŠ¸ (DataFrame ì•ˆì „ ë¹„êµ í¬í•¨)"""
        self.logger.log(f"Testing Node: {node_name}", "NODE")
        if test_description:
            self.logger.log(f"Description: {test_description}", "INFO")
        
        self.logger.indent()
        self.logger.start_timer("node")
        
        try:
            # ì…ë ¥ ìƒíƒœ ë¡œê¹…
            self.logger.log("Input State Analysis:", "DEBUG")
            self.logger.indent()
            for key, value in input_state.items():
                if isinstance(value, (dict, list)):
                    self.logger.log(f"{key}: {type(value).__name__} (length: {len(value)})", "DEBUG")
                elif isinstance(value, pd.DataFrame):
                    self.logger.log(f"{key}: DataFrame {value.shape}", "DEBUG")
                else:
                    self.logger.log(f"{key}: {value}", "DEBUG")
            self.logger.dedent()
            
            # ë…¸ë“œ ì‹¤í–‰
            self.logger.log("Executing node function...", "INFO")
            result_state = node_function(input_state.copy())
            
            # ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
            execution_time = self.logger.end_timer("node")
            
            # ê²°ê³¼ ìƒíƒœ ë¡œê¹… (ì•ˆì „í•œ ë¹„êµ)
            self.logger.log("Output State Analysis:", "DEBUG")
            self.logger.indent()
            
            if isinstance(result_state, dict):
                for key, value in result_state.items():
                    if key not in input_state:
                        if isinstance(value, (dict, list)):
                            self.logger.log(f"NEW {key}: {type(value).__name__} (length: {len(value)})", "DEBUG")
                        elif isinstance(value, pd.DataFrame):
                            self.logger.log(f"NEW {key}: DataFrame {value.shape}", "DEBUG")
                        else:
                            self.logger.log(f"NEW {key}: {value}", "DEBUG")
                    elif self.safe_compare_values(input_state[key], value, key):
                        if isinstance(value, (dict, list)):
                            self.logger.log(f"MODIFIED {key}: {type(value).__name__} (length: {len(value)})", "DEBUG")
                        elif isinstance(value, pd.DataFrame):
                            self.logger.log(f"MODIFIED {key}: DataFrame {value.shape}", "DEBUG")
                        else:
                            self.logger.log(f"MODIFIED {key}: {value}", "DEBUG")
            
            self.logger.dedent()
            
            # ê¸°ë³¸ ê²€ì¦
            if not isinstance(result_state, dict):
                raise AssertionError(f"Node must return dict, got {type(result_state)}")
            
            if 'current_stage' not in result_state:
                self.logger.log("Warning: No 'current_stage' in result", "WARNING")
            
            self.logger.log(f"Node {node_name} executed successfully!", "SUCCESS")
            self.logger.dedent()
            
            return True, result_state, ""
            
        except Exception as e:
            self.logger.log(f"Node {node_name} failed: {str(e)}", "ERROR")
            self.logger.indent()
            self.logger.log("Traceback:", "DEBUG")
            for line in traceback.format_exc().split('\n'):
                if line.strip():
                    self.logger.log(line, "DEBUG")
            self.logger.dedent()
            self.logger.dedent()
            
            return False, {}, str(e)


class Stage1NodeTestsFixed:
    """ìˆ˜ì •ëœ Stage 1 ë…¸ë“œë“¤ì˜ ê°œë³„ í…ŒìŠ¤íŠ¸"""
    
    def __init__(self, tester: ImprovedNodeTester):
        self.tester = tester
        self.logger = tester.logger
    
    def test_survey_loader_node(self, survey_file_path: str) -> Tuple[bool, Dict[str, Any]]:
        """Survey Loader ë…¸ë“œ í…ŒìŠ¤íŠ¸"""
        from nodes.stage1_data_preparation.survey_loader import load_survey_node
        
        state = self.tester.fixtures.create_base_state()
        state['survey_file_path'] = survey_file_path
        
        success, result, error = self.tester.test_single_node(
            "survey_loader", 
            load_survey_node, 
            state,
            "ì„¤ë¬¸ íŒŒì¼ì„ ë¡œë“œí•˜ê³  ì›ì‹œ ë‚´ìš©ì„ ì¶”ì¶œ"
        )
        
        if success:
            # ì¶”ê°€ ê²€ì¦
            if 'raw_survey_info' not in result:
                self.logger.log("Missing 'raw_survey_info' in result", "ERROR")
                success = False
            else:
                survey_info = result['raw_survey_info']
                if 'text' in survey_info and len(survey_info['text']) > 0:
                    self.logger.log(f"Loaded survey content ({len(survey_info['text'])} chars)", "SUCCESS")
                else:
                    self.logger.log("Empty survey content", "WARNING")
        
        return success, result
    
    def test_data_loader_node(self, data_file_path: str) -> Tuple[bool, Dict[str, Any]]:
        """Data Loader ë…¸ë“œ í…ŒìŠ¤íŠ¸"""
        from nodes.stage1_data_preparation.data_loader import load_data_node
        
        state = self.tester.fixtures.create_base_state()
        state['data_file_path'] = data_file_path
        
        success, result, error = self.tester.test_single_node(
            "data_loader",
            load_data_node,
            state,
            "ë°ì´í„° íŒŒì¼ì„ ë¡œë“œí•˜ê³  DataFrameìœ¼ë¡œ ë³€í™˜"
        )
        
        if success:
            # ì¶”ê°€ ê²€ì¦
            if 'raw_data_info' not in result:
                self.logger.log("Missing 'raw_data_info' in result", "ERROR")
                success = False
            elif 'error' in result:
                self.logger.log(f"Data loading error: {result['error']}", "ERROR")
                success = False
            else:
                data_info = result['raw_data_info']
                if 'dataframe_path' in data_info:
                    self.logger.log(f"Data loaded successfully: {data_info['dataframe_path']}", "SUCCESS")
                else:
                    self.logger.log("Missing dataframe_path in data_info", "WARNING")
        
        return success, result
    
    def test_survey_parser_node_with_valid_state(self, survey_info: Dict[str, Any]) -> Tuple[bool, Dict[str, Any]]:
        """Survey Parser ë…¸ë“œ í…ŒìŠ¤íŠ¸ (ìœ íš¨í•œ ìƒíƒœë¡œ)"""
        from nodes.stage1_data_preparation.survey_parser import parse_survey_node
        
        with patch('io_layer.llm.client.LLMClient') as mock_llm_client, \
             patch('config.prompt.prompt_loader.resolve_branch') as mock_resolve_branch:
            
            # Mock ì„¤ì •
            mock_response = {
                "raw": "Survey parsed successfully",
                "parsed": [
                    {
                        "question_number": "Q1",
                        "question_text": "ë¸Œëœë“œì— ëŒ€í•œ ì „ë°˜ì ì¸ ë§Œì¡±ë„ëŠ” ì–´ë– ì‹ ê°€ìš”?",
                        "question_type": "MULTIPLE_CHOICE",
                        "choices": {"1": "ë§¤ìš° ë§Œì¡±", "2": "ë§Œì¡±", "3": "ë³´í†µ", "4": "ë¶ˆë§Œì¡±", "5": "ë§¤ìš° ë¶ˆë§Œì¡±"}
                    },
                    {
                        "question_number": "Q2", 
                        "question_text": "ì œí’ˆ í’ˆì§ˆì— ëŒ€í•œ ì˜ê²¬ì„ ìì„¸íˆ ë§ì”€í•´ì£¼ì„¸ìš”.",
                        "question_type": "OPEN_ENDED",
                        "choices": {}
                    }
                ]
            }
            
            mock_llm_instance = Mock()
            mock_llm_instance.chat.return_value = (mock_response, Mock())
            mock_llm_client.return_value = mock_llm_instance
            
            mock_resolve_branch.return_value = {
                'system': 'You are a survey parser',
                'user_template': 'Parse this survey: {survey_content}',
                'schema': Mock()
            }
            
            state = self.tester.fixtures.create_base_state()
            state['raw_survey_info'] = survey_info  # ì´ì „ ë…¸ë“œì—ì„œ ìƒì„±ëœ ì •ë³´ ì‚¬ìš©
            
            success, result, error = self.tester.test_single_node(
                "survey_parser",
                parse_survey_node,
                state,
                "LLMì„ ì‚¬ìš©í•˜ì—¬ ì„¤ë¬¸ì„ íŒŒì‹±í•˜ê³  ì§ˆë¬¸ êµ¬ì¡° ì¶”ì¶œ"
            )
            
            if success:
                # ì¶”ê°€ ê²€ì¦
                if 'questions' not in result:
                    self.logger.log("Missing 'questions' in result", "ERROR")
                    success = False
                elif not isinstance(result['questions'], dict):
                    self.logger.log("Questions is not a dict", "ERROR")
                    success = False
                else:
                    questions = result['questions']
                    self.logger.log(f"Parsed {len(questions)} questions: {list(questions.keys())}", "SUCCESS")
        
        return success, result


class MockProjectManager:
    """í”„ë¡œì íŠ¸ ë§¤ë‹ˆì € Mock"""
    
    def __init__(self, project_name: str = "test", base_dir: str = "/tmp"):
        self.project_name = project_name
        self.base_dir = base_dir
        self.state_file_path = "/tmp/mock_state.json"
    
    def save_state(self, state, config):
        # ì‹¤ì œë¡œ íŒŒì¼ì„ ì €ì¥í•˜ì§€ ì•Šê³  ì„±ê³µí•œ ê²ƒì²˜ëŸ¼ ì²˜ë¦¬
        pass
    
    def create_project_structure(self):
        return {"project_dir": "/tmp/mock_project"}


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ (ìˆ˜ì •ëœ ë²„ì „)"""
    tester = ImprovedNodeTester()
    
    # í…ŒìŠ¤íŠ¸ ì‹œì‘
    tester.logger.log("ê°œì„ ëœ ì„¸ë¶€ì ì¸ ê°œë³„ ë…¸ë“œ í…ŒìŠ¤íŠ¸ ì‹œì‘", "HEADER")
    tester.logger.start_timer()
    
    try:
        # í”„ë¡œì íŠ¸ ë§¤ë‹ˆì € Mock
        with patch('utils.project_manager.ProjectDirectoryManager', MockProjectManager):
            
            # í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì •
            survey_file_path, data_file_path = tester.setup_test_environment()
            
            # í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤ë“¤ ì´ˆê¸°í™”
            stage1_tests = Stage1NodeTestsFixed(tester)
            
            # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìˆ˜ì§‘
            results = {}
            
            # =============================================================================
            # STAGE 1 NODE TESTS (FIXED)
            # =============================================================================
            tester.logger.log("STAGE 1 ë…¸ë“œë“¤ ê°œë³„ í…ŒìŠ¤íŠ¸ (ìˆ˜ì •ë¨)", "HEADER")
            
            # 1. Survey Loader
            success, survey_state = stage1_tests.test_survey_loader_node(survey_file_path)
            results['survey_loader'] = success
            
            # 2. Data Loader  
            success, data_state = stage1_tests.test_data_loader_node(data_file_path)
            results['data_loader'] = success
            
            # 3. Survey Parser (with valid state)
            if survey_state and 'raw_survey_info' in survey_state:
                success, parser_state = stage1_tests.test_survey_parser_node_with_valid_state(
                    survey_state['raw_survey_info']
                )
                results['survey_parser'] = success
            else:
                tester.logger.log("Survey loader ì‹¤íŒ¨ë¡œ parser í…ŒìŠ¤íŠ¸ ìŠ¤í‚µ", "WARNING")
                results['survey_parser'] = False
            
            # ê°„ë‹¨í•œ í†µê³„í˜• ë…¸ë“œ í…ŒìŠ¤íŠ¸ë“¤
            tester.logger.log("ê°„ë‹¨í•œ ë…¸ë“œ í…ŒìŠ¤íŠ¸ë“¤", "HEADER")
            
            # Router í…ŒìŠ¤íŠ¸
            from router.stage2_router import stage2_type_router
            from nodes.stage2_next_question import stage2_completion_router
            
            # ë¼ìš°í„° í…ŒìŠ¤íŠ¸
            tester.logger.log("ë¼ìš°í„° í…ŒìŠ¤íŠ¸ (ìˆ˜ì •ë¨)", "NODE")
            
            # Stage2 Type Router í…ŒìŠ¤íŠ¸ (ìˆ˜ì •ëœ ë²„ì „)
            test_cases = [
                ({'current_question': {'question_type': 'WORD', 'question_id': 'Q1'}}, 'WORD'),
                ({'current_question': {'question_type': 'SENTENCE', 'question_id': 'Q2'}}, 'SENTENCE'),
                ({'current_question': {'question_type': 'ETC', 'question_id': 'Q3'}}, 'ETC'),
                ({'current_question': None}, '__END__'),
                ({'current_question': {'question_type': 'UNKNOWN', 'question_id': 'Q4'}}, 'ETC'),
            ]
            
            router_success = 0
            for i, (input_state, expected) in enumerate(test_cases):
                try:
                    result = stage2_type_router(input_state)
                    if result == expected:
                        tester.logger.log(f"Router test {i+1}: âœ… PASS", "SUCCESS")
                        router_success += 1
                    else:
                        tester.logger.log(f"Router test {i+1}: âŒ Expected {expected}, got {result}", "ERROR")
                except Exception as e:
                    tester.logger.log(f"Router test {i+1}: âŒ Error {e}", "ERROR")
            
            results['stage2_type_router'] = router_success == len(test_cases)
            
            # Completion Router í…ŒìŠ¤íŠ¸ (ìˆ˜ì •ëœ ë²„ì „)
            completion_test_cases = [
                ({'current_question_idx': 0, 'question_processing_queue': [{'q1': 'data'}, {'q2': 'data'}]}, 'CONTINUE'),
                ({'current_question_idx': 1, 'question_processing_queue': [{'q1': 'data'}, {'q2': 'data'}]}, 'CONTINUE'),
                ({'current_question_idx': 2, 'question_processing_queue': [{'q1': 'data'}, {'q2': 'data'}]}, '__END__'),
                ({'current_question_idx': 0, 'question_processing_queue': []}, '__END__'),
            ]
            
            completion_success = 0
            for i, (input_state, expected) in enumerate(completion_test_cases):
                try:
                    result = stage2_completion_router(input_state)
                    if result == expected:
                        tester.logger.log(f"Completion test {i+1}: âœ… PASS", "SUCCESS")
                        completion_success += 1
                    else:
                        tester.logger.log(f"Completion test {i+1}: âŒ Expected {expected}, got {result}", "ERROR")
                except Exception as e:
                    tester.logger.log(f"Completion test {i+1}: âŒ Error {e}", "ERROR")
            
            results['stage2_completion_router'] = completion_success == len(completion_test_cases)
            
            # =============================================================================
            # ìµœì¢… ê²°ê³¼ ë¦¬í¬íŠ¸
            # =============================================================================
            total_time = tester.logger.end_timer()
            
            tester.logger.log("ê°œì„ ëœ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½", "HEADER")
            
            # ì¹´í…Œê³ ë¦¬ë³„ ê²°ê³¼
            categories = {
                "Core Stage 1 Nodes": [
                    'survey_loader', 'data_loader', 'survey_parser'
                ],
                "Router Tests": [
                    'stage2_type_router', 'stage2_completion_router'
                ]
            }
            
            total_tests = 0
            total_passed = 0
            
            for category, node_list in categories.items():
                tester.logger.log(f"{category}:", "INFO")
                tester.logger.indent()
                
                category_passed = 0
                for node in node_list:
                    if node in results:
                        status = "âœ… PASS" if results[node] else "âŒ FAIL"
                        tester.logger.log(f"{node}: {status}", "INFO")
                        if results[node]:
                            category_passed += 1
                        total_tests += 1
                    else:
                        tester.logger.log(f"{node}: âš ï¸ NOT TESTED", "WARNING")
                
                total_passed += category_passed
                tester.logger.log(f"Category Result: {category_passed}/{len(node_list)} passed", 
                                "SUCCESS" if category_passed == len(node_list) else "WARNING")
                tester.logger.dedent()
            
            # ì „ì²´ ìš”ì•½
            tester.logger.log("ğŸ¯ IMPROVED FINAL SUMMARY", "HEADER")
            tester.logger.log(f"Total Tests: {total_tests}", "INFO")
            tester.logger.log(f"Passed: {total_passed}", "SUCCESS")
            tester.logger.log(f"Failed: {total_tests - total_passed}", "ERROR")
            tester.logger.log(f"Success Rate: {(total_passed/total_tests)*100:.1f}%", "INFO")
            tester.logger.log(f"Total Runtime: {total_time:.2f} seconds", "TIMER")
            
            if total_passed == total_tests:
                tester.logger.log("ğŸ‰ ëª¨ë“  ê°œì„ ëœ í…ŒìŠ¤íŠ¸ê°€ í†µê³¼í–ˆìŠµë‹ˆë‹¤!", "SUCCESS")
            else:
                tester.logger.log(f"âš ï¸ {total_tests - total_passed}ê°œ í…ŒìŠ¤íŠ¸ì—ì„œ ì—¬ì „íˆ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.", "WARNING")
            
            # ê°œë³„ ë…¸ë“œë³„ ìƒì„¸ ë¶„ì„
            tester.logger.log("ğŸ” ê°œë³„ ë…¸ë“œ ìƒì„¸ ë¶„ì„", "HEADER")
            
            if results.get('survey_loader'):
                tester.logger.log("âœ… Survey Loader: íŒŒì¼ ë¡œë”©ê³¼ í…ìŠ¤íŠ¸ ì¶”ì¶œì´ ì •ìƒ ì‘ë™", "SUCCESS")
            
            if results.get('data_loader'):
                tester.logger.log("âœ… Data Loader: Excel íŒŒì¼ ë¡œë”©ê³¼ DataFrame ìƒì„±ì´ ì •ìƒ ì‘ë™", "SUCCESS")
            
            if results.get('survey_parser'):
                tester.logger.log("âœ… Survey Parser: LLMì„ í†µí•œ ì„¤ë¬¸ íŒŒì‹±ì´ ì •ìƒ ì‘ë™", "SUCCESS")
            
            if results.get('stage2_type_router'):
                tester.logger.log("âœ… Type Router: ì§ˆë¬¸ íƒ€ì…ë³„ ë¼ìš°íŒ…ì´ ì •ìƒ ì‘ë™", "SUCCESS")
            
            if results.get('stage2_completion_router'):
                tester.logger.log("âœ… Completion Router: ì™„ë£Œ ìƒíƒœ ì²´í¬ê°€ ì •ìƒ ì‘ë™", "SUCCESS")
            
            tester.logger.log("ê°œì„  ì‚¬í•­:", "INFO")
            tester.logger.indent()
            tester.logger.log("â€¢ DataFrame ì•ˆì „ ë¹„êµ ë¡œì§ ì¶”ê°€", "INFO")
            tester.logger.log("â€¢ Excel íŒŒì¼ì— ID ì»¬ëŸ¼ ì¶”ê°€", "INFO")
            tester.logger.log("â€¢ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ìë™ ìƒì„±", "INFO")
            tester.logger.log("â€¢ Stage tracker Mock ì²˜ë¦¬", "INFO")
            tester.logger.log("â€¢ ìƒíƒœ ì˜ì¡´ì„± ë¬¸ì œ í•´ê²°", "INFO")
            tester.logger.dedent()
            
            return total_passed == total_tests
        
    except Exception as e:
        tester.logger.log(f"ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", "ERROR")
        tester.logger.indent()
        for line in traceback.format_exc().split('\n'):
            if line.strip():
                tester.logger.log(line, "DEBUG")
        tester.logger.dedent()
        return False
        
    finally:
        # í…ŒìŠ¤íŠ¸ í™˜ê²½ ì •ë¦¬
        tester.cleanup_test_environment()


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)